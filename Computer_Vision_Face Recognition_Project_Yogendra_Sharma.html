<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>0c4be5d243584674843b63e4f513898f</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="jPzn42MS0t1s">
<p>##<strong>CV Problem Statement Graded</strong></p>
</div>
<div class="cell code" data-execution_count="14" id="QFQUh81s1WzZ">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
</div>
<div class="cell markdown" id="YK9lUEhCSIZX">
<p>###<strong>1. Import and understand the data.</strong></p>
</div>
<div class="cell markdown" id="h2Lzkwoh1xQO">
<p>####A. Import and read ‘images.npy’.</p>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="xk44dWl11loz" data-outputId="d91d98f3-4c99-494d-f387-48dc7d49d8f5">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the images.npy file with allow_pickle=True</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> np.load(<span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/images.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Access and process the image data</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># For example, let&#39;s print the shape of the loaded images</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Shape of images:&quot;</span>, images.shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Shape of images: (409, 2)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PnTVqlOfOMSB" data-outputId="e7f9e9cc-75dc-45e3-9ccb-42a024de05d9">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>pip install opencv<span class="op">-</span>python</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)
Requirement already satisfied: numpy&gt;=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="guq0Q0PqOTkp" data-outputId="4f00aaa0-3042-4509-dbdd-746a871d74c6">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>pip install numpy</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="awcgwbxCOB3O" data-outputId="9da4b1db-4e0b-4df7-b860-77de3a35083f">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to read images from a ZIP file</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_images_from_zip(zip_file_path):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_file:</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>            image_names <span class="op">=</span> zip_file.namelist()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> []</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> image_name <span class="kw">in</span> image_names:</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> zip_file.<span class="bu">open</span>(image_name) <span class="im">as</span> image_file:</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                    image_data <span class="op">=</span> image_file.read()</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>                    image_np_array <span class="op">=</span> np.frombuffer(image_data, np.uint8)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>                    image <span class="op">=</span> cv2.imdecode(image_np_array, cv2.IMREAD_COLOR)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>                    images.append(image)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> images</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Error reading images from ZIP file:&quot;</span>, <span class="bu">str</span>(e))</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace &#39;training_images-20211126T092819Z-001.zip&#39; with your ZIP file path</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;training_images-20211126T092819Z-001.zip&#39;</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> read_images_from_zip(zip_file_path)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> images:</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Successfully read </span><span class="sc">{</span><span class="bu">len</span>(images)<span class="sc">}</span><span class="ss"> images from the ZIP file.&quot;</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Failed to read images from the ZIP file.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Error reading images from ZIP file: [Errno 2] No such file or directory: &#39;training_images-20211126T092819Z-001.zip&#39;
Failed to read images from the ZIP file.
</code></pre>
</div>
</div>
<div class="cell markdown" id="BXIXLj5F2wg5">
<p>####B. Split the data into Features(X) &amp; labels(Y). Unify shape
of all the images. <strong>Imp Note:</strong> Replace all the pixels
within masked area with 1. <strong>Hint:</strong> X will comprise of
array of image whereas Y will comprise of coordinates of the mask(human
face). Observe: data[0], data[0][0], data[0][1].</p>
</div>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="AvHNeb3H22oc" data-outputId="f10f4005-2914-4f6d-95f5-39eb5889b413">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_zip(zip_file_path, extract_to_path):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        zip_ref.extractall(extract_to_path)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage:</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace &#39;your_zip_file.zip&#39; with the actual name of your zip file</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace &#39;extracted_data_folder&#39; with the desired folder where you want to extract the data</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images-20211126T092819Z-001.zip&#39;</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>extract_to_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06&#39;</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the output directory if it doesn&#39;t exist</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(extract_to_path):</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    os.makedirs(extract_to_path)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function to extract the zip data</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>extract_zip(zip_file_path, extract_to_path)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Data extracted successfully.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Data extracted successfully.
</code></pre>
</div>
</div>
<div class="cell markdown" id="Xkd_GnHId4yI">
<p>####C. Split the data into train and test[400:9].</p>
</div>
<div class="cell code" data-execution_count="20"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="TREUCyzydj6Q" data-outputId="7290a636-5c20-4fce-fb93-1473f6d4ca18">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to read images from a ZIP file</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_images_from_zip(zip_file_path):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_file:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>            image_names <span class="op">=</span> zip_file.namelist()</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> []</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> image_name <span class="kw">in</span> image_names:</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> zip_file.<span class="bu">open</span>(image_name) <span class="im">as</span> image_file:</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>                    image_data <span class="op">=</span> image_file.read()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>                    image_np_array <span class="op">=</span> np.frombuffer(image_data, np.uint8)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>                    image <span class="op">=</span> cv2.imdecode(image_np_array, cv2.IMREAD_COLOR)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>                    images.append(image)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> images</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Error reading images from ZIP file:&quot;</span>, <span class="bu">str</span>(e))</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace the ZIP file path with your actual path</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images-20211126T092819Z-001.zip&#39;</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> read_images_from_zip(zip_file_path)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> images:</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Successfully read </span><span class="sc">{</span><span class="bu">len</span>(images)<span class="sc">}</span><span class="ss"> images from the ZIP file.&quot;</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split the data into train and test sets with a ratio of 400:9</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    train_images <span class="op">=</span> images[:<span class="dv">400</span>]</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    test_images <span class="op">=</span> images[<span class="dv">400</span>:<span class="dv">409</span>]  <span class="co"># Selecting 9 images after the first 400</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Number of training images: </span><span class="sc">{</span><span class="bu">len</span>(train_images)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Number of test images: </span><span class="sc">{</span><span class="bu">len</span>(test_images)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Failed to read images from the ZIP file.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Successfully read 1091 images from the ZIP file.
Number of training images: 400
Number of test images: 9
</code></pre>
</div>
</div>
<div class="cell markdown" id="-_G7Kl0Mebaw">
<p>####D. Select random image from the train data and display original
image and masked image.</p>
</div>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:358}"
id="jQTT2YkNee2O" data-outputId="bf37b052-565d-4955-d545-a274d40f12f2">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to read images from a ZIP file</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_images_from_zip(zip_file_path):</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_file:</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>            image_names <span class="op">=</span> zip_file.namelist()</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> []</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> image_name <span class="kw">in</span> image_names:</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> zip_file.<span class="bu">open</span>(image_name) <span class="im">as</span> image_file:</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>                    image_data <span class="op">=</span> image_file.read()</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>                    image_np_array <span class="op">=</span> np.frombuffer(image_data, np.uint8)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>                    image <span class="op">=</span> cv2.imdecode(image_np_array, cv2.IMREAD_COLOR)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>                    images.append(image)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> images</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Error reading images from ZIP file:&quot;</span>, <span class="bu">str</span>(e))</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace the ZIP file path with your actual path</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images-20211126T092819Z-001.zip&#39;</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> read_images_from_zip(zip_file_path)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> images:</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Successfully read </span><span class="sc">{</span><span class="bu">len</span>(images)<span class="sc">}</span><span class="ss"> images from the ZIP file.&quot;</span>)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split the data into train and test sets with a ratio of 400:9</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    train_images <span class="op">=</span> images[:<span class="dv">400</span>]</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    test_images <span class="op">=</span> images[<span class="dv">400</span>:<span class="dv">409</span>]  <span class="co"># Selecting 9 images after the first 400</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select a random image from the training set</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>    random_index <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(train_images) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>    selected_image <span class="op">=</span> train_images[random_index]</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mask for the selected image (thresholding)</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>    gray_image <span class="op">=</span> cv2.cvtColor(selected_image, cv2.COLOR_BGR2GRAY)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    _, binary_mask <span class="op">=</span> cv2.threshold(gray_image, <span class="dv">100</span>, <span class="dv">255</span>, cv2.THRESH_BINARY)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the original image and masked image</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>    plt.imshow(cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB))</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Original Image&quot;</span>)</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>    plt.imshow(binary_mask, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Masked Image&quot;</span>)</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Failed to read images from the ZIP file.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Successfully read 1091 images from the ZIP file.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/ca6f5a0a3a4e8618502abf6a805d4c444a8d7a43.png" /></p>
</div>
</div>
<div class="cell markdown" id="W-sj94ODSuPS">
<p>###<strong>2. Model building:</strong></p>
</div>
<div class="cell markdown" id="nq1fRz0fS7Ds">
<p>####A. Design a face mask detection model. Hint: 1. Use MobileNet
architecture for initial pre-trained non-trainable layers. Hint: 2. Add
appropriate Upsampling layers to imitate U-net architecture.</p>
</div>
<div class="cell code" data-execution_count="22" id="geREEMoXgbR4">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="23"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PCS73x7tgfuY" data-outputId="d1238bb2-8d70-4f47-af5b-427383ad5d6d">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow.keras <span class="im">as</span> keras</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(keras.__version__)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>2.12.0
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="FPa2PE0jgkE-" data-outputId="77ad4e31-86b2-4378-d74b-ff3d61b29ea7">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>pip install tensorflow</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)
Requirement already satisfied: absl-py&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)
Requirement already satisfied: astunparse&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)
Requirement already satisfied: flatbuffers&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)
Requirement already satisfied: gast&lt;=0.4.0,&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)
Requirement already satisfied: google-pasta&gt;=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)
Requirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)
Requirement already satisfied: h5py&gt;=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)
Requirement already satisfied: jax&gt;=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)
Requirement already satisfied: keras&lt;2.13,&gt;=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)
Requirement already satisfied: libclang&gt;=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)
Requirement already satisfied: numpy&lt;1.24,&gt;=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)
Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)
Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)
Requirement already satisfied: tensorboard&lt;2.13,&gt;=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)
Requirement already satisfied: tensorflow-estimator&lt;2.13,&gt;=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)
Requirement already satisfied: typing-extensions&gt;=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)
Requirement already satisfied: wrapt&lt;1.15,&gt;=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)
Requirement already satisfied: tensorflow-io-gcs-filesystem&gt;=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)
Requirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse&gt;=1.6.0-&gt;tensorflow) (0.40.0)
Requirement already satisfied: ml-dtypes&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax&gt;=0.3.15-&gt;tensorflow) (0.2.0)
Requirement already satisfied: scipy&gt;=1.7 in /usr/local/lib/python3.10/dist-packages (from jax&gt;=0.3.15-&gt;tensorflow) (1.10.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.4.3)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.27.1)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.7.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.3.6)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (5.3.1)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.3.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.4)
Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.1.3)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.2.2)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="25"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="bPqaBegiVpRa" data-outputId="09e1d6ad-d6c1-42dd-b944-9ab919f8166d">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the zip file</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images-20211126T092819Z-001.zip&#39;</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Directory where the data will be extracted</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>extracted_data_dir <span class="op">=</span> <span class="st">&#39;/content/training_images&#39;</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the zip file</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    zip_ref.extractall(extracted_data_dir)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the contents of the extracted directory</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(os.listdir(extracted_data_dir))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;training_images&#39;]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:358}"
id="PsTAj2D_P43u" data-outputId="9ca35142-383f-43d1-92eb-b770aba1b0b3">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to read images from a ZIP file</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_images_from_zip(zip_file_path):</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_file:</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>            image_names <span class="op">=</span> zip_file.namelist()</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> []</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> image_name <span class="kw">in</span> image_names:</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> zip_file.<span class="bu">open</span>(image_name) <span class="im">as</span> image_file:</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>                    image_data <span class="op">=</span> image_file.read()</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>                    image_np_array <span class="op">=</span> np.frombuffer(image_data, np.uint8)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>                    image <span class="op">=</span> cv2.imdecode(image_np_array, cv2.IMREAD_COLOR)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>                    images.append(image)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> images</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Error reading images from ZIP file:&quot;</span>, <span class="bu">str</span>(e))</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace the ZIP file path with your actual path</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images-20211126T092819Z-001.zip&#39;</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> read_images_from_zip(zip_file_path)</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> images:</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Successfully read </span><span class="sc">{</span><span class="bu">len</span>(images)<span class="sc">}</span><span class="ss"> images from the ZIP file.&quot;</span>)</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split the data into train and test sets with a ratio of 400:9</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    train_images <span class="op">=</span> images[:<span class="dv">400</span>]</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>    test_images <span class="op">=</span> images[<span class="dv">400</span>:<span class="dv">409</span>]  <span class="co"># Selecting 9 images after the first 400</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select a random image from the training set</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>    random_index <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(train_images) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>    selected_image <span class="op">=</span> train_images[random_index]</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mask for the selected image (thresholding)</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>    gray_image <span class="op">=</span> cv2.cvtColor(selected_image, cv2.COLOR_BGR2GRAY)</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>    _, binary_mask <span class="op">=</span> cv2.threshold(gray_image, <span class="dv">100</span>, <span class="dv">255</span>, cv2.THRESH_BINARY)</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the original image and masked image</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>    plt.imshow(cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB))</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Original Image&quot;</span>)</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>    plt.imshow(binary_mask, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Masked Image&quot;</span>)</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Failed to read images from the ZIP file.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Successfully read 1091 images from the ZIP file.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/567d7e9e5e46a4e09ca90c12b8c289e1362406a5.png" /></p>
</div>
</div>
<div class="cell markdown" id="ZEtzN2B-VaJh">
<p>####B. Design your own Dice Co-efficient and Loss function.</p>
</div>
<div class="cell code" data-execution_count="27" id="rrbKYq3MaeZJ">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dice_coefficient(y_true, y_pred, smooth<span class="op">=</span><span class="fl">1e-7</span>):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    intersection <span class="op">=</span> tf.reduce_sum(y_true <span class="op">*</span> y_pred)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    dice <span class="op">=</span> (<span class="fl">2.0</span> <span class="op">*</span> intersection <span class="op">+</span> smooth) <span class="op">/</span> (tf.reduce_sum(y_true) <span class="op">+</span> tf.reduce_sum(y_pred) <span class="op">+</span> smooth)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dice</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dice_loss(y_true, y_pred):</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">1.0</span> <span class="op">-</span> dice_coefficient(y_true, y_pred)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="28" id="u-dC5rr7bMeH">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Define the U-Net-like model with MobileNetV2 base layers and additional upsampling layers</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model():</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load pre-trained MobileNetV2 (without top classification layers)</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    base_model <span class="op">=</span> MobileNetV2(weights<span class="op">=</span><span class="st">&#39;imagenet&#39;</span>, include_top<span class="op">=</span><span class="va">False</span>, input_shape<span class="op">=</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">3</span>))</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add upsampling layers to create U-Net-like architecture</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">3</span>))</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encoder (MobileNet layers)</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    encoder_features <span class="op">=</span> base_model(inputs)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decoder (Upsampling layers)</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2DTranspose(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)(encoder_features)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(x)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sample the encoder block_12_expand_relu to match the size of x</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    up_block_12 <span class="op">=</span> UpSampling2D(size<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))(base_model.get_layer(<span class="st">&#39;block_12_expand_relu&#39;</span>).output)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> concatenate([x, up_block_12], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2DTranspose(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)(x)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(x)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sample the encoder block_6_expand_relu to match the size of x</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    up_block_6 <span class="op">=</span> UpSampling2D(size<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))(base_model.get_layer(<span class="st">&#39;block_6_expand_relu&#39;</span>).output)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> concatenate([x, up_block_6], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2DTranspose(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)(x)</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(x)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sample the encoder block_3_expand_relu to match the size of x</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>    up_block_3 <span class="op">=</span> UpSampling2D(size<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">16</span>))(base_model.get_layer(<span class="st">&#39;block_3_expand_relu&#39;</span>).output)</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> concatenate([x, up_block_3], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add final classification layer for face mask detection</span></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Conv2D(<span class="dv">1</span>, (<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>)(x)  <span class="co"># Binary classification for mask detection</span></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the model</span></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs, outputs)</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div>
</div>
<div class="cell markdown" id="Hqy84VuqjSCt">
<p>####C. Train and tune the model as required.</p>
</div>
<div class="cell code" data-execution_count="29" id="73ruhZNYgPEi">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Define the U-Net-like model with MobileNetV2 base layers and additional upsampling layers</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model():</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load pre-trained MobileNetV2 (without top classification layers)</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    base_model <span class="op">=</span> MobileNetV2(weights<span class="op">=</span><span class="st">&#39;imagenet&#39;</span>, include_top<span class="op">=</span><span class="va">False</span>, input_shape<span class="op">=</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">3</span>))</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add upsampling layers to create U-Net-like architecture</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">3</span>))</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encoder (MobileNet layers)</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    encoder_features <span class="op">=</span> base_model(inputs)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decoder (Upsampling layers)</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2DTranspose(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)(encoder_features)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(x)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sample the encoder block_6_expand_relu to match the size of x</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    up_block_6 <span class="op">=</span> UpSampling2D(size<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))(base_model.get_layer(<span class="st">&#39;block_6_expand_relu&#39;</span>).output)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> concatenate([x, up_block_6], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2DTranspose(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)(x)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(x)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sample the encoder block_3_expand_relu to match the size of x</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    up_block_3 <span class="op">=</span> UpSampling2D(size<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))(base_model.get_layer(<span class="st">&#39;block_3_expand_relu&#39;</span>).output)</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> concatenate([x, up_block_3], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Up-sample the encoder block_1_expand_relu to match the size of x</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    up_block_1 <span class="op">=</span> UpSampling2D(size<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">16</span>))(base_model.get_layer(<span class="st">&#39;block_1_expand_relu&#39;</span>).output)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> concatenate([x, up_block_1], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add final classification layer for face mask detection</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Conv2D(<span class="dv">1</span>, (<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>)(x)  <span class="co"># Binary classification for mask detection</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the model</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs, outputs)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div>
</div>
<div class="cell markdown" id="go4IT8jmjZ31">
<p>To drop additional features from a dataset, you need to have some
relevant functional knowledge or domain expertise about the data and the
problem you are trying to solve. Here are a few scenarios where you
might consider dropping features:</p>
<p><strong>Redundant or highly correlated features:</strong> If you have
features that are highly correlated with each other, keeping all of them
may not provide much additional information. In such cases, you can drop
one of the correlated features to reduce multicollinearity and simplify
the model.</p>
<p><strong>Irrelevant features:</strong> Some features may not have any
meaningful impact on the target variable or may not contribute to the
overall prediction accuracy. These features could be dropped as they add
unnecessary complexity to the model without providing valuable
insights.</p>
<p><strong>Features with high missing values:</strong> If a feature has
a significant number of missing values, it may not be useful for
analysis or modeling. Dropping such features can help to simplify the
dataset and avoid imputing a large number of missing values.</p>
<p><strong>Outliers or constant value features:</strong> Features that
contain mostly outliers or have a constant value across all rows may not
provide meaningful information. Removing such features can help to
improve the model's performance and interpretability.</p>
<p><strong>Dimensionality reduction:</strong> In cases where you have a
high-dimensional dataset, dropping some features can be beneficial to
reduce the curse of dimensionality. Techniques such as Principal
Component Analysis (PCA) or feature selection algorithms can help
identify the most informative features to retain.</p>
<p>It's important to note that the decision to drop features should be
based on a careful analysis of the data and the specific problem you are
working on. Domain knowledge, exploratory data analysis, and
experimentation with different feature subsets can guide you in making
informed decisions about which features to drop.</p>
</div>
<div class="cell markdown" id="lSSqPXwMj9jF">
<p>####D. Evaluate and share insights on performance of the model.</p>
</div>
<div class="cell code" id="erWHIfZpkGZU">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> load_model</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the trained model</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> load_model(<span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/mask_detection_model.h5&#39;</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 7: Evaluate the model on the validation dataset</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>validation_steps <span class="op">=</span> <span class="bu">len</span>(val_data)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>validation_result <span class="op">=</span> model.evaluate(val_data, steps<span class="op">=</span>validation_steps)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 8: Print the evaluation results</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Loss:&quot;</span>, validation_result[<span class="dv">0</span>])</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Accuracy:&quot;</span>, validation_result[<span class="dv">1</span>])</span></code></pre></div>
</div>
<div class="cell markdown" id="hbNTL_bduEQt">
<p>Insights from the performance evaluation:</p>
<p><strong>Validation Loss:</strong> This metric measures how well the
model is performing on the validation dataset. A lower validation loss
indicates better performance, meaning the model is making more accurate
predictions.</p>
<p><strong>Validation Accuracy:</strong> This metric shows the
proportion of correctly classified samples out of the total number of
samples in the validation dataset. A higher validation accuracy
indicates that the model is more successful in identifying whether a
person is wearing a face mask or not.</p>
<p>It's important to note that the performance of the model may vary
depending on the size and quality of the dataset, the model
architecture, and the training parameters. To further improve the
model's performance, you can consider data augmentation, hyperparameter
tuning, and potentially exploring more complex architectures if
needed.</p>
<p>Additionally, you can visualize some sample predictions on the
validation dataset to get an intuitive understanding of how the model is
performing on individual images. This will allow you to identify cases
where the model is making correct or incorrect predictions and gain
insights into potential areas for improvement.</p>
</div>
<div class="cell markdown" id="P1hCWdqYkS7k">
<p>####3. Test the model predictions on the test image: ‘image with
index 3 in the test data’ and visualise the predicted masks on the faces
in the image.</p>
</div>
<div class="cell code" id="d7xu-N1hsSaK">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Load the test image</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>test_image_path <span class="op">=</span> <span class="st">&#39;/path/to/test_image.jpeg&#39;</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>test_image <span class="op">=</span> cv2.imread(test_image_path)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>test_image_rgb <span class="op">=</span> cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Preprocess the test image</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>test_image_resized <span class="op">=</span> cv2.resize(test_image_rgb, (<span class="dv">128</span>, <span class="dv">128</span>))</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>test_image_normalized <span class="op">=</span> test_image_resized <span class="op">/</span> <span class="fl">255.0</span>  <span class="co"># Normalize to [0, 1]</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>test_image_input <span class="op">=</span> np.expand_dims(test_image_normalized, axis<span class="op">=</span><span class="dv">0</span>)  <span class="co"># Add batch dimension</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Make predictions using the model</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>predicted_mask <span class="op">=</span> model.predict(test_image_input)[<span class="dv">0</span>]</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Visualize the original image and the predicted mask overlay</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Original Image</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>plt.imshow(test_image_rgb)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Original Image&#39;</span>)</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted Mask Overlay</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>plt.imshow(test_image_rgb)</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>plt.imshow(predicted_mask, cmap<span class="op">=</span><span class="st">&#39;jet&#39;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)  <span class="co"># Overlay the predicted mask</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Predicted Mask Overlay&#39;</span>)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="cell markdown" id="sACX4ZBukrBk">
<p>To make relevant modifications on the data using both
functional/logical reasoning and assumptions, it's important to
understand the specific context and problem you are working on. Without
detailed information about your dataset and objectives, I can provide
you with general examples of common modifications. However, it's crucial
to adapt these modifications to your specific situation.</p>
<p><strong>Handling Missing Values:</strong> If the missing values are
minimal, you can impute them using appropriate techniques such as mean,
median, mode, or regression imputation.</p>
<p>If the missing values are significant, you may consider removing the
rows or columns with missing values if they don't contain critical
information.</p>
<p>In some cases, missing values can be indicative of a specific
category or meaning. You can treat missing values as a separate category
or create a new feature to capture the missingness.</p>
<p><strong>Encoding Categorical Variables:</strong> Convert categorical
variables into numerical representations suitable for machine learning
algorithms. Common approaches include one-hot encoding, label encoding,
or target encoding. For ordinal variables, ensure proper encoding that
captures the inherent order or hierarchy among categories.</p>
<p><strong>Feature Scaling:</strong> Normalize or standardize numerical
features to ensure they are on a similar scale, which can improve the
performance of certain algorithms. Scaling is particularly important for
algorithms that rely on distance-based calculations, such as k-means
clustering or support vector machines.</p>
<p><strong>Handling Outliers:</strong> Identify and handle outliers
using appropriate techniques, such as replacing them with the median or
mean, capping them at a certain threshold, or using robust statistical
methods. Consider the domain knowledge and context to determine if
outliers are genuine or erroneous values, and treat them
accordingly.</p>
<p><strong>Feature Engineering:</strong> Create new features that
provide additional information or capture meaningful patterns in the
data. This can include mathematical transformations, interaction terms,
aggregations, or deriving features from timestamps or text data.
Domain-specific knowledge is crucial for effective feature engineering,
as it allows you to incorporate relevant information and assumptions
about the problem.</p>
<p><strong>Dimensionality Reduction:</strong> If you have a
high-dimensional dataset, consider applying dimensionality reduction
techniques such as Principal Component Analysis (PCA) or feature
selection algorithms to reduce the number of features while retaining
important information. These modifications provide a starting point, but
it's important to adapt them based on your specific dataset, problem,
and domain knowledge. Consider the assumptions and reasoning behind each
modification to ensure they align with your goals and the
characteristics of your data.</p>
</div>
<div class="cell markdown" id="1hc0_1MJlRcS">
<p>###<strong>Part B</strong></p>
</div>
<div class="cell markdown" id="orSoV8jWlXH4">
<p>####1. Read/import images from folder ‘training_images’.</p>
</div>
<div class="cell code" data-execution_count="46" id="nl71EWCclilq">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the folder containing the images</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize an empty list to store the image data</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>images_data <span class="op">=</span> []</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the files in the folder</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> filename <span class="kw">in</span> os.listdir(folder_path):</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the file is an image (you may add additional checks if needed)</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> filename.endswith(<span class="st">&#39;.jpg&#39;</span>) <span class="kw">or</span> filename.endswith(<span class="st">&#39;.png&#39;</span>):</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Construct the full file path</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        file_path <span class="op">=</span> os.path.join(folder_path, filename)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Open the image using PIL</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(file_path)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the image to numpy array (optional step)</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>        image_array <span class="op">=</span> np.array(image)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the image data to the list</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>        images_data.append(image_array)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a><span class="co"># The variable &#39;images_data&#39; now contains a list of numpy arrays, each representing an image in the folder.</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="co"># You can use this list for further processing or analysis with the images.</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="47"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:223}"
id="Yke0TnhV47VQ" data-outputId="2b5e7529-107c-4114-cc0a-5bfc1c25d3f2">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the folder containing the images</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize an empty list to store the image data</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>images_data <span class="op">=</span> []</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the files in the folder</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> filename <span class="kw">in</span> os.listdir(folder_path):</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the file is an image (you may add additional checks if needed)</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> filename.endswith(<span class="st">&#39;.jpg&#39;</span>) <span class="kw">or</span> filename.endswith(<span class="st">&#39;.png&#39;</span>):</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Construct the full file path</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        file_path <span class="op">=</span> os.path.join(folder_path, filename)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Open the image using PIL</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(file_path)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the image data to the list</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>        images_data.append(image)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Display some sample images from the list</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>num_images_to_display <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_images_to_display):</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, num_images_to_display, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    plt.imshow(images_data[i])</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/8d72088b3f096b54a4d719fbd2e425f76711ad82.png" /></p>
</div>
</div>
<div class="cell markdown" id="wL12Kccg5e-e">
<p>####2. Write a loop which will iterate through all the images in the
‘training_images’ folder and detect the faces present on all the images.
<strong>Hint:</strong> You can use ’haarcascade_frontalface_default.xml’
from internet to detect faces which is available open source.</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="yLE0xnQL5nf3" data-outputId="61dd4e2d-a41f-4c0f-904b-787eefdf81cc">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab.patches <span class="im">import</span> cv2_imshow</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Haar Cascade classifier for face detection</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>face_cascade <span class="op">=</span> cv2.CascadeClassifier(cv2.data.haarcascades <span class="op">+</span> <span class="st">&#39;haarcascade_frontalface_default.xml&#39;</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the folder containing the images</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the files in the folder</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> filename <span class="kw">in</span> os.listdir(folder_path):</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the file is an image (you may add additional checks if needed)</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> filename.endswith(<span class="st">&#39;.jpg&#39;</span>) <span class="kw">or</span> filename.endswith(<span class="st">&#39;.png&#39;</span>):</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Construct the full file path</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>        file_path <span class="op">=</span> os.path.join(folder_path, filename)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read the image using OpenCV</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> cv2.imread(file_path)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the image to grayscale (required for face detection)</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        gray_image <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Detect faces in the grayscale image</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>        faces <span class="op">=</span> face_cascade.detectMultiScale(gray_image, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>, minSize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw rectangles around the detected faces</span></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>            cv2.rectangle(image, (x, y), (x<span class="op">+</span>w, y<span class="op">+</span>h), (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Display the image with detected faces</span></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>        cv2_imshow(image)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/f11c17e4d4b0467039928f9fdc93d84ba8d2ee1a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/b33501761df3d29a0e4c5aeeb79b458760fd90f5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/4f3ecf7e419b9e423f2b784da73e366e4093adde.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/2d089dde0a8f096629940e665dde98c69fa61ee7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/fbd2d448d5a37bf48ab48839009fc44ab7271d12.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/83e0ef40049ef30792b0ce54e3eaafaf219a3e66.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/2709c0035583788f7f1f9d8e25cb5950000e62b8.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/e03d49a5f9981ca2a551fde13a697251cdd02abd.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/64b2ae793c0123ca6158abbc0ebb368f175b613f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/f0a20954a1886c39f1eede36937c30d87751bc61.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/52943d804cf291c933a657feb5939b55c1466265.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/c68c4164fa50be97a505e23cdc6a22326371a711.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/d44d4c7ad8a86f055fee7c9b0c86a07c94752ceb.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/d3bd2fc29fa94cf99f981f7a3092b79ff8959500.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/0f4756e2eb8e58c05cf88561cece86b63a9560c1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/bd7954ec324895e52f33d7ce998b40c6cb7a5c8d.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/d0a5c406c0efdfe0ace5e974f3d663a50e3247d1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/3492fc663c34b8c6bec16b88df8825b6d4312e46.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/5c792609ba8c74680727dcde2b046a37b19c6fc3.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/b75ac1dc809ff22cb42148418c377e10b8139163.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/178bcbd3fd505be826a403e90c781d943e7cd878.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/27df20e678e4f5782730c038cc02ad95fa8fa7e7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/040466eaec33fc0152eae61baa75c96710989b22.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/ad00a2c8a08254eef45d3682a46f0de8f26fab9d.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/640b21ac6a8225d71bc320a2b309cf9db7c98219.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/1fa8682afdbba820e0aa8df7091f4d44fb8c12b6.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/a58074c048eb8e8762af0511052f27f6c36ce980.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/a0d7563879efdf39e49431b78ac0f349847e72b5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/bffe0fdb95f616613e46ca108387d009ec338a18.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/a29615e98590d8a4ba7f6c932787a7fae4c40eb4.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/0370287a21dbd67824b50a0418ddc817f81d683b.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/4e8614b9c09e4d6578bede0a1ba101b19fbbb0a2.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/2fc773aa6ebfb292584a39e071a8d3e52e04a01d.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/43c71df2e763c0ef827afa40bfb2d8cab1339aa1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/8013fb872ce2792a2172358984c704e2c77e8200.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/b71ababb0dfe12d0cffd595dce261dbba0c12836.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/aded34bb2e1621f803e1f3b3af2149031571d815.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/72e10dada95da878704ff881044dd25984841fe8.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/8871dd98f8984edfda494028d6caf0839095f23f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/70ceec42378f411a691e2e7d28e3ff19d5f38ebc.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/ea23c75cf157b233ccaf50447b5457faa4d9797a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/7b9c55dc4855622c786491272b9257b468b440c5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/6446d6b67aca046165afa87b04199dbd210016a1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/7811e2729fcd4a7db1b5d1e59237154058e2d4bd.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/3a2aeacf3eb1ad07c9067a07df38dfc4fd64ddf8.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/5743f448408187b2515443a272419133df1b0437.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/0fa0ed444fd21fd887ce6cecd2e51bc3197671fb.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/b2bf77d6919874dc0d17fa2f5a7cdd0ee465c466.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/5021a1f6ce847566e31a7ba3a3ae0273756ad32f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/9e1c65ca042af1f64ee96bc47bcf06c573e7c099.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/ced0859e713ee4cf9eb25198a2afe072581c19c7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/b220f500de40b64d701d0367fd8ab02100e723bb.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/04619870656566bbf6713c712d631e2ad4305cb2.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/2a5fbe0fd9a9e921b3955a6e92103cd4ec957028.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/610b465aae702c29e323dfc55044c4da1ec6d38b.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/22635914c47cb8a7d949c813d3a1246125587acb.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/dbbd2f150b34330df8a20740faf16d8d934e3843.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/1811ed5b9ac441c4eafb8b601dbc2679a6f4d1ed.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/3a89b0c2208ee0b3a4d1abdc6f42cbc43fe38af0.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/68fcd93ccf02897875035a92f446f8348f0623e5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/a3020540087cf03b46656c52690210a0eab9e6dc.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/92620ba9c810a689f530708f1928decb621d313a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/c2415710e5d73bb1bbff654e5972edf2f93963b5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/4ec19bebebd427dde446b8d3034333bbf9dbe683.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/f5e9dce2b1ac84da295a60626f90a3c0b44ed39e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/13320d00d1fbcff3d69ba7fa986ea1c7ce7a63ad.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/3d7b45ec5ab2de009b66c565ef679c1905e6c009.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/0307336552eb95b5b6d2518afc0f0738ca7dc952.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/e5bcf7d7a57f69190cda5c28a5031975b955fb4e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/3b2175d2e005ac91db0f1d39e5e92e910b13dfa5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/2e42f6bd75f473493963e4d5afd90f2a7a33f448.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/5fbb12d4e8a8f6c820ac0ae9f77d8c7fca519e6f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/db4d332d8d0a0ab7618466b7454b6f72e7ac09af.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/7bbdeef403b76f1129b44e588e6dbcf1516dc7bd.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/23ee51f03a5350931fa3945dc745052fb31f0d8c.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/415e3f2f4b39de0a7f33657f8c33b007d4dce788.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/234a1c51505cb57ace97a7188ea2aea3a1618175.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/41101f8ea15c000a7af8b6fecf225a1b90eaaed1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/548fda6b43eb704821bf35a3d3c3135dca3050af.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/9c793ab131a80aa36c1b5dd62341aa9fb87f7703.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Buffered data was truncated after reaching the output size limit.</code></pre>
</div>
</div>
<div class="cell markdown" id="OmO1rIDy7TvR">
<p>####3. From the same loop above, extract metadata of the faces and
write into a DataFrame.</p>
</div>
<div class="cell code" data-execution_count="51"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="GoaV0_BT8acn" data-outputId="1ea4efbc-238d-443c-f189-192289b07874">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Haar Cascade classifier for face detection</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>face_cascade <span class="op">=</span> cv2.CascadeClassifier(cv2.data.haarcascades <span class="op">+</span> <span class="st">&#39;haarcascade_frontalface_default.xml&#39;</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the folder containing the images</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty list to store the metadata</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>metadata_list <span class="op">=</span> []</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the files in the folder</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> filename <span class="kw">in</span> os.listdir(folder_path):</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the file is an image (you may add additional checks if needed)</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> filename.endswith(<span class="st">&#39;.jpg&#39;</span>) <span class="kw">or</span> filename.endswith(<span class="st">&#39;.png&#39;</span>):</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Construct the full file path</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>        file_path <span class="op">=</span> os.path.join(folder_path, filename)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read the image using OpenCV</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> cv2.imread(file_path)</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the image to grayscale (required for face detection)</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>        gray_image <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Detect faces in the grayscale image</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>        faces <span class="op">=</span> face_cascade.detectMultiScale(gray_image, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>, minSize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the metadata of each face to the list</span></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>            metadata_list.append({<span class="st">&#39;x&#39;</span>: x, <span class="st">&#39;y&#39;</span>: y, <span class="st">&#39;w&#39;</span>: w, <span class="st">&#39;h&#39;</span>: h, <span class="st">&#39;Total_Faces&#39;</span>: <span class="bu">len</span>(faces), <span class="st">&#39;Images_Name&#39;</span>: filename})</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame from the metadata list</span></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a>df_metadata <span class="op">=</span> pd.DataFrame(metadata_list)</span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the DataFrame</span></span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_metadata)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>       x    y    w    h  Total_Faces     Images_Name
0    146  113  392  392            1  real_00835.jpg
1    125  133  415  415            1  real_00941.jpg
2    125  180  333  333            1  real_00928.jpg
3     61   77  474  474            1  real_00931.jpg
4     75  163  399  399            1  real_00874.jpg
..   ...  ...  ...  ...          ...             ...
944  117   43  465  465            1  real_00994.jpg
945  127  147  362  362            2  real_00827.jpg
946   51  260   58   58            2  real_00827.jpg
947  115  160  411  411            1  real_00876.jpg
948   73  124  444  444            1  real_00871.jpg

[949 rows x 6 columns]
</code></pre>
</div>
</div>
<div class="cell markdown" id="8o9FKHQX9-jK">
<p>####4. Save the output Dataframe in .csv format.</p>
</div>
<div class="cell code" data-execution_count="52"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="1hIPdNDJ-BQa" data-outputId="0edd183e-a21c-4809-964f-0c239141a386">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Haar Cascade classifier for face detection</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>face_cascade <span class="op">=</span> cv2.CascadeClassifier(cv2.data.haarcascades <span class="op">+</span> <span class="st">&#39;haarcascade_frontalface_default.xml&#39;</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the folder containing the images</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty list to store the metadata</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>metadata_list <span class="op">=</span> []</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the files in the folder</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> filename <span class="kw">in</span> os.listdir(folder_path):</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the file is an image (you may add additional checks if needed)</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> filename.endswith(<span class="st">&#39;.jpg&#39;</span>) <span class="kw">or</span> filename.endswith(<span class="st">&#39;.png&#39;</span>):</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Construct the full file path</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>        file_path <span class="op">=</span> os.path.join(folder_path, filename)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read the image using OpenCV</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> cv2.imread(file_path)</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the image to grayscale (required for face detection)</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>        gray_image <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Detect faces in the grayscale image</span></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>        faces <span class="op">=</span> face_cascade.detectMultiScale(gray_image, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>, minSize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the metadata of each face to the list</span></span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>            metadata_list.append({<span class="st">&#39;x&#39;</span>: x, <span class="st">&#39;y&#39;</span>: y, <span class="st">&#39;w&#39;</span>: w, <span class="st">&#39;h&#39;</span>: h, <span class="st">&#39;Total_Faces&#39;</span>: <span class="bu">len</span>(faces), <span class="st">&#39;Images_Name&#39;</span>: filename})</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame from the metadata list</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>df_metadata <span class="op">=</span> pd.DataFrame(metadata_list)</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the DataFrame as a .csv file</span></span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>output_csv_file <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/faces_metadata.csv&#39;</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>df_metadata.to_csv(output_csv_file, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the DataFrame (optional)</span></span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_metadata)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>       x    y    w    h  Total_Faces     Images_Name
0    146  113  392  392            1  real_00835.jpg
1    125  133  415  415            1  real_00941.jpg
2    125  180  333  333            1  real_00928.jpg
3     61   77  474  474            1  real_00931.jpg
4     75  163  399  399            1  real_00874.jpg
..   ...  ...  ...  ...          ...             ...
944  117   43  465  465            1  real_00994.jpg
945  127  147  362  362            2  real_00827.jpg
946   51  260   58   58            2  real_00827.jpg
947  115  160  411  411            1  real_00876.jpg
948   73  124  444  444            1  real_00871.jpg

[949 rows x 6 columns]
</code></pre>
</div>
</div>
<div class="cell markdown" id="69ugUxPcmcxQ">
<p>###<strong>Part C:</strong></p>
</div>
<div class="cell markdown" id="_IIbhLI8mhAw">
<p>####1. Unzip, read and Load data(‘PINS.zip’) into session.</p>
</div>
<div class="cell code" data-execution_count="53" id="coXPcO3ansYv">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the ZIP file</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>zip_file_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/PINS.zip&#39;</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Directory to extract the contents of the ZIP file</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>extracted_folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/PINS&#39;</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Unzip the file</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(zip_file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    zip_ref.extractall(extracted_folder_path)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co"># List the files in the extracted folder</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>extracted_files <span class="op">=</span> os.listdir(extracted_folder_path)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data (example: read and print the first few lines of a text file)</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> file_name <span class="kw">in</span> extracted_files:</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> file_name.endswith(<span class="st">&#39;.txt&#39;</span>):</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        file_path <span class="op">=</span> os.path.join(extracted_folder_path, file_name)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(file_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):  <span class="co"># Print the first 5 lines of each text file</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="bu">file</span>.readline())</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Load any other data you have in the extracted folder as needed (images, etc.)</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a><span class="co"># You can use the appropriate libraries (e.g., OpenCV for images) to read and process the data.</span></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean up (optional): Remove the extracted folder if needed</span></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Use with caution as this will permanently delete the extracted data</span></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a><span class="co"># os.rmdir(extracted_folder_path)</span></span></code></pre></div>
</div>
<div class="cell markdown" id="CyliJJLvoSFz">
<p>####2. Write function to create metadata of the image. Hint: Metadata
means derived information from the available data which can be useful
for particular problem statement.</p>
</div>
<div class="cell code" data-execution_count="57"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="JGjolvPjomzy" data-outputId="33b4c67a-307c-48d6-8182-877e8cae91c4">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_image_metadata(image_path):</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load the image using PIL (Python Imaging Library)</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(image_path)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the image to grayscale</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        gray_image <span class="op">=</span> image.convert(<span class="st">&#39;L&#39;</span>)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the PIL image to numpy array for OpenCV processing</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        image_np <span class="op">=</span> np.array(gray_image)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load the Haar cascade classifier for face detection</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        face_cascade <span class="op">=</span> cv2.CascadeClassifier(cv2.data.haarcascades <span class="op">+</span> <span class="st">&#39;haarcascade_frontalface_default.xml&#39;</span>)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Detect faces in the image</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>        faces <span class="op">=</span> face_cascade.detectMultiScale(image_np, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>, minSize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a list to store the metadata for each face</span></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>        metadata <span class="op">=</span> []</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract metadata for each detected face</span></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>            face_metadata <span class="op">=</span> {</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;x&#39;</span>: x,</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;y&#39;</span>: y,</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;w&#39;</span>: w,</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;h&#39;</span>: h</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>            metadata.append(face_metadata)</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add additional metadata if needed</span></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> metadata</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage:</span></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> <span class="st">&#39;/path/to/your/image.jpg&#39;</span></span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>metadata <span class="op">=</span> create_image_metadata(image_path)</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> metadata:</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metadata)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Error: [Errno 2] No such file or directory: &#39;/path/to/your/image.jpg&#39;
</code></pre>
</div>
</div>
<div class="cell markdown" id="FGGH6-DgqUO2">
<p>####3. Write a loop to iterate through each and every image and
create metadata for all the images.</p>
</div>
<div class="cell code" data-execution_count="60"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="GMBAxosxqgiG" data-outputId="76d136ed-d3e2-48aa-e06e-c8411571905c">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Folder path containing the images</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>images_folder_path <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># List all image files in the folder</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>file_list <span class="op">=</span> os.listdir(images_folder_path)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through each image and create metadata</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(file_list)):</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    image_path <span class="op">=</span> os.path.join(images_folder_path, file_list[i])</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    metadata <span class="op">=</span> create_image_metadata(image_path)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> metadata:</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Metadata for </span><span class="sc">{</span>file_list[i]<span class="sc">}</span><span class="ss">:&quot;</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(metadata)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Metadata for real_00835.jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 113, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00941.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 133, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00928.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 180, &#39;w&#39;: 333, &#39;h&#39;: 333}]


Metadata for real_00931.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 77, &#39;w&#39;: 474, &#39;h&#39;: 474}]


Metadata for real_00874.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 163, &#39;w&#39;: 399, &#39;h&#39;: 399}]


Metadata for real_00887.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 84, &#39;w&#39;: 454, &#39;h&#39;: 454}]


Metadata for real_00842.jpg:
[{&#39;x&#39;: 159, &#39;y&#39;: 126, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00838.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 80, &#39;w&#39;: 470, &#39;h&#39;: 470}]


Metadata for real_00785.jpg:
[{&#39;x&#39;: 147, &#39;y&#39;: 140, &#39;w&#39;: 393, &#39;h&#39;: 393}]


Metadata for real_00799.jpg:
[{&#39;x&#39;: 55, &#39;y&#39;: 106, &#39;w&#39;: 456, &#39;h&#39;: 456}]


Metadata for real_00815.jpg:
[{&#39;x&#39;: 16, &#39;y&#39;: 170, &#39;w&#39;: 407, &#39;h&#39;: 407}]


Metadata for real_00880.jpg:
[{&#39;x&#39;: 224, &#39;y&#39;: 326, &#39;w&#39;: 62, &#39;h&#39;: 62}]


Metadata for real_00902.jpg:
[{&#39;x&#39;: 55, &#39;y&#39;: 77, &#39;w&#39;: 472, &#39;h&#39;: 472}]


Metadata for real_00896.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 69, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00927.jpg:
[{&#39;x&#39;: 187, &#39;y&#39;: 168, &#39;w&#39;: 365, &#39;h&#39;: 365}]


Metadata for real_00911.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 120, &#39;w&#39;: 462, &#39;h&#39;: 462}, {&#39;x&#39;: 524, &#39;y&#39;: 233, &#39;w&#39;: 55, &#39;h&#39;: 55}]


Metadata for real_00823.jpg:
[{&#39;x&#39;: 103, &#39;y&#39;: 200, &#39;w&#39;: 354, &#39;h&#39;: 354}]


Metadata for real_00939.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 43, &#39;w&#39;: 449, &#39;h&#39;: 449}]


Metadata for real_00873.jpg:
[{&#39;x&#39;: 29, &#39;y&#39;: 19, &#39;w&#39;: 530, &#39;h&#39;: 530}]


Metadata for real_00932.jpg:
[{&#39;x&#39;: 32, &#39;y&#39;: 62, &#39;w&#39;: 474, &#39;h&#39;: 474}]


Metadata for real_00886.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 131, &#39;w&#39;: 407, &#39;h&#39;: 407}]


Metadata for real_00920.jpg:
[{&#39;x&#39;: 94, &#39;y&#39;: 114, &#39;w&#39;: 456, &#39;h&#39;: 456}]


Metadata for real_00919.jpg:
[{&#39;x&#39;: 131, &#39;y&#39;: 139, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00808.jpg:
[{&#39;x&#39;: 139, &#39;y&#39;: 133, &#39;w&#39;: 409, &#39;h&#39;: 409}]


Metadata for real_00891.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 155, &#39;w&#39;: 334, &#39;h&#39;: 334}]


Metadata for real_00863.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 153, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00848.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 175, &#39;w&#39;: 343, &#39;h&#39;: 343}]


Metadata for real_00803.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 28, &#39;w&#39;: 469, &#39;h&#39;: 469}]


Metadata for real_00844.jpg:
[{&#39;x&#39;: 153, &#39;y&#39;: 109, &#39;w&#39;: 399, &#39;h&#39;: 399}]


Metadata for real_00836.jpg:
[{&#39;x&#39;: 21, &#39;y&#39;: 77, &#39;w&#39;: 454, &#39;h&#39;: 454}]


Metadata for real_00868.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 109, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00869.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 32, &#39;w&#39;: 488, &#39;h&#39;: 488}]


Metadata for real_00839.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 167, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00789.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 89, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00899.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 151, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00837.jpg:
[{&#39;x&#39;: 504, &#39;y&#39;: 109, &#39;w&#39;: 67, &#39;h&#39;: 67}, {&#39;x&#39;: 100, &#39;y&#39;: 217, &#39;w&#39;: 332, &#39;h&#39;: 332}]


Metadata for real_00834.jpg:
[{&#39;x&#39;: 131, &#39;y&#39;: 236, &#39;w&#39;: 336, &#39;h&#39;: 336}]


Metadata for real_00787.jpg:
[{&#39;x&#39;: 15, &#39;y&#39;: 51, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00783.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 33, &#39;w&#39;: 476, &#39;h&#39;: 476}]


Metadata for real_00882.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 93, &#39;w&#39;: 464, &#39;h&#39;: 464}]


Metadata for real_00826.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 179, &#39;w&#39;: 348, &#39;h&#39;: 348}]


Metadata for real_00843.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 178, &#39;w&#39;: 362, &#39;h&#39;: 362}]


Metadata for real_00801.jpg:
[{&#39;x&#39;: 243, &#39;y&#39;: 279, &#39;w&#39;: 193, &#39;h&#39;: 193}]


Metadata for real_00881.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 161, &#39;w&#39;: 397, &#39;h&#39;: 397}]


Metadata for real_00812.jpg:
[{&#39;x&#39;: 54, &#39;y&#39;: 47, &#39;w&#39;: 500, &#39;h&#39;: 500}]


Metadata for real_00810.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 155, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00847.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 63, &#39;w&#39;: 505, &#39;h&#39;: 505}]


Metadata for real_00858.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 119, &#39;w&#39;: 429, &#39;h&#39;: 429}]


Metadata for real_00833.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 53, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_00901.jpg:
[{&#39;x&#39;: 213, &#39;y&#39;: 168, &#39;w&#39;: 146, &#39;h&#39;: 146}]


Metadata for real_00933.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 108, &#39;w&#39;: 426, &#39;h&#39;: 426}]


Metadata for real_00908.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 132, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00889.jpg:
[{&#39;x&#39;: 122, &#39;y&#39;: 178, &#39;w&#39;: 376, &#39;h&#39;: 376}]


Metadata for real_00867.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 45, &#39;w&#39;: 478, &#39;h&#39;: 478}, {&#39;x&#39;: 204, &#39;y&#39;: 238, &#39;w&#39;: 290, &#39;h&#39;: 290}]


Metadata for real_00828.jpg:
[{&#39;x&#39;: 118, &#39;y&#39;: 65, &#39;w&#39;: 459, &#39;h&#39;: 459}]


Metadata for real_00817.jpg:
[{&#39;x&#39;: 131, &#39;y&#39;: 193, &#39;w&#39;: 344, &#39;h&#39;: 344}]


Metadata for real_00923.jpg:
[{&#39;x&#39;: 133, &#39;y&#39;: 258, &#39;w&#39;: 322, &#39;h&#39;: 322}]


Metadata for real_00905.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 175, &#39;w&#39;: 357, &#39;h&#39;: 357}, {&#39;x&#39;: 470, &#39;y&#39;: 254, &#39;w&#39;: 109, &#39;h&#39;: 109}, {&#39;x&#39;: 501, &#39;y&#39;: 405, &#39;w&#39;: 52, &#39;h&#39;: 52}]


Metadata for real_00860.jpg:
[{&#39;x&#39;: 39, &#39;y&#39;: 23, &#39;w&#39;: 504, &#39;h&#39;: 504}]


Metadata for real_00937.jpg:
[{&#39;x&#39;: 91, &#39;y&#39;: 196, &#39;w&#39;: 357, &#39;h&#39;: 357}]


Metadata for real_00938.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 106, &#39;w&#39;: 447, &#39;h&#39;: 447}]


Metadata for real_00821.jpg:
[{&#39;x&#39;: 165, &#39;y&#39;: 140, &#39;w&#39;: 354, &#39;h&#39;: 354}]


Metadata for real_00816.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 162, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00900.jpg:
[{&#39;x&#39;: 129, &#39;y&#39;: 99, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00894.jpg:
[{&#39;x&#39;: 300, &#39;y&#39;: 280, &#39;w&#39;: 75, &#39;h&#39;: 75}]


Metadata for real_00907.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 121, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00922.jpg:
[{&#39;x&#39;: 43, &#39;y&#39;: 156, &#39;w&#39;: 355, &#39;h&#39;: 355}, {&#39;x&#39;: 439, &#39;y&#39;: 188, &#39;w&#39;: 127, &#39;h&#39;: 127}]


Metadata for real_00813.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 82, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00913.jpg:
[{&#39;x&#39;: 42, &#39;y&#39;: 72, &#39;w&#39;: 522, &#39;h&#39;: 522}]


Metadata for real_00885.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 77, &#39;w&#39;: 481, &#39;h&#39;: 481}]


Metadata for real_00916.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 88, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_00866.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 82, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00914.jpg:
[{&#39;x&#39;: 172, &#39;y&#39;: 133, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00790.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 169, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00792.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 91, &#39;w&#39;: 453, &#39;h&#39;: 453}]


Metadata for real_00820.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 107, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_00646.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 16, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00707.jpg:
[{&#39;x&#39;: 153, &#39;y&#39;: 132, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00699.jpg:
[{&#39;x&#39;: 101, &#39;y&#39;: 170, &#39;w&#39;: 383, &#39;h&#39;: 383}]


Metadata for real_00662.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 181, &#39;w&#39;: 376, &#39;h&#39;: 376}]


Metadata for real_01046.jpg:
[{&#39;x&#39;: 144, &#39;y&#39;: 177, &#39;w&#39;: 381, &#39;h&#39;: 381}]


Metadata for real_00754.jpg:
[{&#39;x&#39;: 94, &#39;y&#39;: 144, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00766.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 141, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00757.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 170, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00929.jpg:
[{&#39;x&#39;: 434, &#39;y&#39;: 76, &#39;w&#39;: 97, &#39;h&#39;: 97}, {&#39;x&#39;: 105, &#39;y&#39;: 202, &#39;w&#39;: 382, &#39;h&#39;: 382}]


Metadata for real_00758.jpg:
[{&#39;x&#39;: 42, &#39;y&#39;: 155, &#39;w&#39;: 400, &#39;h&#39;: 400}]


Metadata for real_00737.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 177, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00648.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 92, &#39;w&#39;: 459, &#39;h&#39;: 459}]


Metadata for real_00739.jpg:
[{&#39;x&#39;: 126, &#39;y&#39;: 165, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00687.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 103, &#39;w&#39;: 457, &#39;h&#39;: 457}]


Metadata for real_00752.jpg:
[{&#39;x&#39;: 151, &#39;y&#39;: 184, &#39;w&#39;: 382, &#39;h&#39;: 382}]


Metadata for real_00717.jpg:
[{&#39;x&#39;: 219, &#39;y&#39;: 153, &#39;w&#39;: 354, &#39;h&#39;: 354}]


Metadata for real_00763.jpg:
[{&#39;x&#39;: 135, &#39;y&#39;: 98, &#39;w&#39;: 450, &#39;h&#39;: 450}]


Metadata for real_00656.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 332, &#39;w&#39;: 80, &#39;h&#39;: 80}]


Metadata for real_00660.jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 159, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00644.jpg:
[{&#39;x&#39;: 148, &#39;y&#39;: 221, &#39;w&#39;: 291, &#39;h&#39;: 291}]


Metadata for real_00704.jpg:
[{&#39;x&#39;: 399, &#39;y&#39;: 314, &#39;w&#39;: 51, &#39;h&#39;: 51}]


Metadata for real_00647.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 124, &#39;w&#39;: 393, &#39;h&#39;: 393}]


Metadata for real_00740.jpg:
[{&#39;x&#39;: 16, &#39;y&#39;: 121, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_00672.jpg:
[{&#39;x&#39;: 323, &#39;y&#39;: 178, &#39;w&#39;: 149, &#39;h&#39;: 149}]


Metadata for real_00665.jpg:
[{&#39;x&#39;: 39, &#39;y&#39;: 133, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00694.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 167, &#39;w&#39;: 376, &#39;h&#39;: 376}]


Metadata for real_00738.jpg:
[{&#39;x&#39;: 148, &#39;y&#39;: 185, &#39;w&#39;: 376, &#39;h&#39;: 376}]


Metadata for real_00749.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 123, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00643.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 66, &#39;w&#39;: 434, &#39;h&#39;: 434}]


Metadata for real_00673.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 125, &#39;w&#39;: 413, &#39;h&#39;: 413}]


Metadata for real_00778.jpg:
[{&#39;x&#39;: 161, &#39;y&#39;: 137, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00654.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 76, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00735.jpg:
[{&#39;x&#39;: 505, &#39;y&#39;: 164, &#39;w&#39;: 60, &#39;h&#39;: 60}, {&#39;x&#39;: 79, &#39;y&#39;: 155, &#39;w&#39;: 385, &#39;h&#39;: 385}]


Metadata for real_00724.jpg:
[{&#39;x&#39;: 147, &#39;y&#39;: 94, &#39;w&#39;: 362, &#39;h&#39;: 362}]


Metadata for real_00773.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 156, &#39;w&#39;: 383, &#39;h&#39;: 383}]


Metadata for real_00732.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 156, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00765.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 90, &#39;w&#39;: 463, &#39;h&#39;: 463}]


Metadata for real_00664.jpg:
[{&#39;x&#39;: 139, &#39;y&#39;: 109, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00751.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 158, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00750.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 167, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00657.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 98, &#39;w&#39;: 425, &#39;h&#39;: 425}]


Metadata for real_00781.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 149, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00653.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 206, &#39;w&#39;: 255, &#39;h&#39;: 255}]


Metadata for real_00710.jpg:
[{&#39;x&#39;: 63, &#39;y&#39;: 208, &#39;w&#39;: 370, &#39;h&#39;: 370}]


Metadata for real_01074.jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 97, &#39;w&#39;: 431, &#39;h&#39;: 431}]


Metadata for real_00659.jpg:
[{&#39;x&#39;: 167, &#39;y&#39;: 206, &#39;w&#39;: 359, &#39;h&#39;: 359}]


Metadata for real_00768.jpg:
[{&#39;x&#39;: 134, &#39;y&#39;: 161, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_00674.jpg:
[{&#39;x&#39;: 156, &#39;y&#39;: 366, &#39;w&#39;: 78, &#39;h&#39;: 78}]


Metadata for real_00635.jpg:
[{&#39;x&#39;: 35, &#39;y&#39;: 136, &#39;w&#39;: 409, &#39;h&#39;: 409}]


Metadata for real_00756.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 140, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00770.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 143, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_00734.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 105, &#39;w&#39;: 445, &#39;h&#39;: 445}]


Metadata for real_00767.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 135, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00693.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 156, &#39;w&#39;: 383, &#39;h&#39;: 383}]


Metadata for real_00859.jpg:
[{&#39;x&#39;: 131, &#39;y&#39;: 158, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_01028.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 142, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00915.jpg:
[{&#39;x&#39;: 58, &#39;y&#39;: 170, &#39;w&#39;: 379, &#39;h&#39;: 379}]


Metadata for real_00702.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 108, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00733.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 85, &#39;w&#39;: 443, &#39;h&#39;: 443}, {&#39;x&#39;: 353, &#39;y&#39;: 166, &#39;w&#39;: 131, &#39;h&#39;: 131}]


Metadata for real_00924.jpg:
[{&#39;x&#39;: 25, &#39;y&#39;: 10, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00930.jpg:
[{&#39;x&#39;: 149, &#39;y&#39;: 153, &#39;w&#39;: 366, &#39;h&#39;: 366}]


Metadata for real_00731.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 150, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00708.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 147, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00712.jpg:
[{&#39;x&#39;: 140, &#39;y&#39;: 180, &#39;w&#39;: 350, &#39;h&#39;: 350}]


Metadata for real_00713.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 94, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00701.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 144, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00776.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 181, &#39;w&#39;: 400, &#39;h&#39;: 400}]


Metadata for real_00726.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 148, &#39;w&#39;: 377, &#39;h&#39;: 377}]


Metadata for real_00769.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 67, &#39;w&#39;: 393, &#39;h&#39;: 393}]


Metadata for real_00677.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 135, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00649.jpg:
[{&#39;x&#39;: 118, &#39;y&#39;: 23, &#39;w&#39;: 471, &#39;h&#39;: 471}]


Metadata for real_00725.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 107, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_00651.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 105, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00650.jpg:
[{&#39;x&#39;: 384, &#39;y&#39;: 109, &#39;w&#39;: 61, &#39;h&#39;: 61}]


Metadata for real_00764.jpg:
[{&#39;x&#39;: 67, &#39;y&#39;: 108, &#39;w&#39;: 448, &#39;h&#39;: 448}]


Metadata for real_00675.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 64, &#39;w&#39;: 468, &#39;h&#39;: 468}]


Metadata for real_00637.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 162, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00811.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 91, &#39;w&#39;: 446, &#39;h&#39;: 446}]


Metadata for real_00760.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 171, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00780.jpg:
[{&#39;x&#39;: 158, &#39;y&#39;: 192, &#39;w&#39;: 356, &#39;h&#39;: 356}]


Metadata for real_00728.jpg:
[{&#39;x&#39;: 32, &#39;y&#39;: 21, &#39;w&#39;: 526, &#39;h&#39;: 526}]


Metadata for real_00755.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 144, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00774.jpg:
[{&#39;x&#39;: 104, &#39;y&#39;: 192, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00676.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 137, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_00777.jpg:
[{&#39;x&#39;: 132, &#39;y&#39;: 143, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00753.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 159, &#39;w&#39;: 397, &#39;h&#39;: 397}]


Metadata for real_00678.jpg:
[{&#39;x&#39;: 35, &#39;y&#39;: 98, &#39;w&#39;: 439, &#39;h&#39;: 439}]


Metadata for real_00718.jpg:
[{&#39;x&#39;: 309, &#39;y&#39;: 133, &#39;w&#39;: 273, &#39;h&#39;: 273}, {&#39;x&#39;: 358, &#39;y&#39;: 373, &#39;w&#39;: 161, &#39;h&#39;: 161}]


Metadata for real_00745.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 132, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00696.jpg:
[{&#39;x&#39;: 50, &#39;y&#39;: 32, &#39;w&#39;: 488, &#39;h&#39;: 488}]


Metadata for real_00669.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 121, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00736.jpg:
[{&#39;x&#39;: 228, &#39;y&#39;: 192, &#39;w&#39;: 308, &#39;h&#39;: 308}]


Metadata for real_00744.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 168, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00688.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 243, &#39;w&#39;: 147, &#39;h&#39;: 147}]


Metadata for real_00667.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 92, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00641.jpg:
[{&#39;x&#39;: 138, &#39;y&#39;: 127, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00695.jpg:
[{&#39;x&#39;: 11, &#39;y&#39;: 135, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00685.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 50, &#39;w&#39;: 456, &#39;h&#39;: 456}]


Metadata for real_00663.jpg:
[{&#39;x&#39;: 134, &#39;y&#39;: 66, &#39;w&#39;: 433, &#39;h&#39;: 433}]


Metadata for real_00642.jpg:
[{&#39;x&#39;: 80, &#39;y&#39;: 163, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00640.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 97, &#39;w&#39;: 445, &#39;h&#39;: 445}]


Metadata for real_00714.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 113, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00682.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 193, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00668.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 181, &#39;w&#39;: 365, &#39;h&#39;: 365}]


Metadata for real_00730.jpg:
[{&#39;x&#39;: 165, &#39;y&#39;: 167, &#39;w&#39;: 402, &#39;h&#39;: 402}, {&#39;x&#39;: 81, &#39;y&#39;: 249, &#39;w&#39;: 139, &#39;h&#39;: 139}]


Metadata for real_00782.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 166, &#39;w&#39;: 378, &#39;h&#39;: 378}]


Metadata for real_00698.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 110, &#39;w&#39;: 406, &#39;h&#39;: 406}]


Metadata for real_00720.jpg:
[{&#39;x&#39;: 55, &#39;y&#39;: 165, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00747.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 208, &#39;w&#39;: 352, &#39;h&#39;: 352}]


Metadata for real_00743.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 69, &#39;w&#39;: 485, &#39;h&#39;: 485}, {&#39;x&#39;: 206, &#39;y&#39;: 460, &#39;w&#39;: 132, &#39;h&#39;: 132}]


Metadata for real_00681.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 138, &#39;w&#39;: 379, &#39;h&#39;: 379}]


Metadata for real_00727.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 140, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00684.jpg:
[{&#39;x&#39;: 267, &#39;y&#39;: 257, &#39;w&#39;: 78, &#39;h&#39;: 78}]


Metadata for real_00721.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 86, &#39;w&#39;: 348, &#39;h&#39;: 348}]


Metadata for real_00666.jpg:
[{&#39;x&#39;: 407, &#39;y&#39;: 21, &#39;w&#39;: 133, &#39;h&#39;: 133}]


Metadata for real_00690.jpg:
[{&#39;x&#39;: 128, &#39;y&#39;: 129, &#39;w&#39;: 429, &#39;h&#39;: 429}]


Metadata for real_00703.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 41, &#39;w&#39;: 488, &#39;h&#39;: 488}]


Metadata for real_00670.jpg:
[{&#39;x&#39;: 37, &#39;y&#39;: 33, &#39;w&#39;: 483, &#39;h&#39;: 483}]


Metadata for real_00636.jpg:
[{&#39;x&#39;: 23, &#39;y&#39;: 51, &#39;w&#39;: 475, &#39;h&#39;: 475}]


Metadata for real_00706.jpg:
[{&#39;x&#39;: 287, &#39;y&#39;: 419, &#39;w&#39;: 62, &#39;h&#39;: 62}]


Metadata for real_00689.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 175, &#39;w&#39;: 379, &#39;h&#39;: 379}]


Metadata for real_00639.jpg:
[{&#39;x&#39;: 33, &#39;y&#39;: 76, &#39;w&#39;: 477, &#39;h&#39;: 477}]


Metadata for real_00680.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 100, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_00715.jpg:
[{&#39;x&#39;: 135, &#39;y&#39;: 90, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_00759.jpg:
[{&#39;x&#39;: 217, &#39;y&#39;: 197, &#39;w&#39;: 330, &#39;h&#39;: 330}]


Metadata for real_00645.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 124, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00679.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 68, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00604.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 189, &#39;w&#39;: 374, &#39;h&#39;: 374}]


Metadata for real_00771.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 165, &#39;w&#39;: 365, &#39;h&#39;: 365}]


Metadata for real_00527.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 105, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00719.jpg:
[{&#39;x&#39;: 118, &#39;y&#39;: 204, &#39;w&#39;: 343, &#39;h&#39;: 343}]


Metadata for real_00629.jpg:
[{&#39;x&#39;: 162, &#39;y&#39;: 82, &#39;w&#39;: 167, &#39;h&#39;: 167}, {&#39;x&#39;: 58, &#39;y&#39;: 204, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00541.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 141, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00506.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 53, &#39;w&#39;: 485, &#39;h&#39;: 485}]


Metadata for real_00516.jpg:
[{&#39;x&#39;: 39, &#39;y&#39;: 123, &#39;w&#39;: 450, &#39;h&#39;: 450}]


Metadata for real_00555.jpg:
[{&#39;x&#39;: 88, &#39;y&#39;: 132, &#39;w&#39;: 406, &#39;h&#39;: 406}]


Metadata for real_00532.jpg:
[{&#39;x&#39;: 166, &#39;y&#39;: 195, &#39;w&#39;: 362, &#39;h&#39;: 362}]


Metadata for real_00599.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 114, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00600.jpg:
[{&#39;x&#39;: 107, &#39;y&#39;: 158, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00849.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 129, &#39;w&#39;: 397, &#39;h&#39;: 397}]


Metadata for real_00491.jpg:
[{&#39;x&#39;: 26, &#39;y&#39;: 114, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00496.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 182, &#39;w&#39;: 364, &#39;h&#39;: 364}]


Metadata for real_00494.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 137, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00588.jpg:
[{&#39;x&#39;: 139, &#39;y&#39;: 151, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00494(1).jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 137, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00621.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 175, &#39;w&#39;: 406, &#39;h&#39;: 406}]


Metadata for real_00545.jpg:
[{&#39;x&#39;: 67, &#39;y&#39;: 84, &#39;w&#39;: 451, &#39;h&#39;: 451}]


Metadata for real_00624.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 122, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00605.jpg:
[{&#39;x&#39;: 244, &#39;y&#39;: 386, &#39;w&#39;: 159, &#39;h&#39;: 159}]


Metadata for real_00521.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 148, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00940.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 71, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_00595.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 121, &#39;w&#39;: 439, &#39;h&#39;: 439}]


Metadata for real_00495.jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 150, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00633.jpg:
[{&#39;x&#39;: 162, &#39;y&#39;: 92, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00561.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 150, &#39;w&#39;: 359, &#39;h&#39;: 359}]


Metadata for real_00505.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 76, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00634.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 167, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00497.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 220, &#39;w&#39;: 343, &#39;h&#39;: 343}]


Metadata for real_00512.jpg:
[{&#39;x&#39;: 57, &#39;y&#39;: 26, &#39;w&#39;: 494, &#39;h&#39;: 494}]


Metadata for real_00564.jpg:
[{&#39;x&#39;: 50, &#39;y&#39;: 157, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_00558.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 188, &#39;w&#39;: 372, &#39;h&#39;: 372}]


Metadata for real_00526.jpg:
[{&#39;x&#39;: 142, &#39;y&#39;: 137, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00518.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 141, &#39;w&#39;: 406, &#39;h&#39;: 406}, {&#39;x&#39;: 454, &#39;y&#39;: 232, &#39;w&#39;: 109, &#39;h&#39;: 109}]


Metadata for real_00594.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 116, &#39;w&#39;: 449, &#39;h&#39;: 449}]


Metadata for real_00625.jpg:
[{&#39;x&#39;: 306, &#39;y&#39;: 287, &#39;w&#39;: 240, &#39;h&#39;: 240}]


Metadata for real_00585.jpg:
[{&#39;x&#39;: 107, &#39;y&#39;: 152, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00568.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 21, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00559.jpg:
[{&#39;x&#39;: 121, &#39;y&#39;: 187, &#39;w&#39;: 385, &#39;h&#39;: 385}]


Metadata for real_00601.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 203, &#39;w&#39;: 334, &#39;h&#39;: 334}]


Metadata for real_00592.jpg:
[{&#39;x&#39;: 140, &#39;y&#39;: 141, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00591.jpg:
[{&#39;x&#39;: 160, &#39;y&#39;: 176, &#39;w&#39;: 377, &#39;h&#39;: 377}]


Metadata for real_00528.jpg:
[{&#39;x&#39;: 86, &#39;y&#39;: 88, &#39;w&#39;: 449, &#39;h&#39;: 449}]


Metadata for real_00533.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 107, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00571.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 95, &#39;w&#39;: 443, &#39;h&#39;: 443}]


Metadata for real_00515.jpg:
[{&#39;x&#39;: 31, &#39;y&#39;: 64, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_00499.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 179, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00498.jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 85, &#39;w&#39;: 478, &#39;h&#39;: 478}]


Metadata for real_00587.jpg:
[{&#39;x&#39;: 58, &#39;y&#39;: 83, &#39;w&#39;: 454, &#39;h&#39;: 454}]


Metadata for real_00503.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 116, &#39;w&#39;: 436, &#39;h&#39;: 436}]


Metadata for real_00619.jpg:
[{&#39;x&#39;: 121, &#39;y&#39;: 148, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_00553.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 85, &#39;w&#39;: 468, &#39;h&#39;: 468}]


Metadata for real_00537.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 78, &#39;w&#39;: 473, &#39;h&#39;: 473}]


Metadata for real_00485.jpg:
[{&#39;x&#39;: 46, &#39;y&#39;: 167, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00570.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 130, &#39;w&#39;: 400, &#39;h&#39;: 400}]


Metadata for real_00575.jpg:
[{&#39;x&#39;: 101, &#39;y&#39;: 100, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00557.jpg:
[{&#39;x&#39;: 167, &#39;y&#39;: 149, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00495(1).jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 150, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00490.jpg:
[{&#39;x&#39;: 103, &#39;y&#39;: 146, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00576.jpg:
[{&#39;x&#39;: 9, &#39;y&#39;: 34, &#39;w&#39;: 433, &#39;h&#39;: 433}]


Metadata for real_00606.jpg:
[{&#39;x&#39;: 103, &#39;y&#39;: 177, &#39;w&#39;: 376, &#39;h&#39;: 376}, {&#39;x&#39;: 19, &#39;y&#39;: 298, &#39;w&#39;: 88, &#39;h&#39;: 88}]


Metadata for real_00574.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 176, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00577.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 304, &#39;w&#39;: 51, &#39;h&#39;: 51}]


Metadata for real_00626.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 134, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00572.jpg:
[{&#39;x&#39;: 162, &#39;y&#39;: 226, &#39;w&#39;: 347, &#39;h&#39;: 347}]


Metadata for real_00597.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 54, &#39;w&#39;: 475, &#39;h&#39;: 475}]


Metadata for real_00566.jpg:
[{&#39;x&#39;: 174, &#39;y&#39;: 132, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00563.jpg:
[{&#39;x&#39;: 40, &#39;y&#39;: 174, &#39;w&#39;: 332, &#39;h&#39;: 332}]


Metadata for real_00616.jpg:
[{&#39;x&#39;: 48, &#39;y&#39;: 162, &#39;w&#39;: 337, &#39;h&#39;: 337}]


Metadata for real_00535.jpg:
[{&#39;x&#39;: 109, &#39;y&#39;: 151, &#39;w&#39;: 409, &#39;h&#39;: 409}]


Metadata for real_00612.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 125, &#39;w&#39;: 442, &#39;h&#39;: 442}]


Metadata for real_00631.jpg:
[{&#39;x&#39;: 48, &#39;y&#39;: 119, &#39;w&#39;: 433, &#39;h&#39;: 433}]


Metadata for real_00523.jpg:
[{&#39;x&#39;: 116, &#39;y&#39;: 151, &#39;w&#39;: 382, &#39;h&#39;: 382}]


Metadata for real_00530.jpg:
[{&#39;x&#39;: 182, &#39;y&#39;: 110, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00546.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 113, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00524.jpg:
[{&#39;x&#39;: 94, &#39;y&#39;: 170, &#39;w&#39;: 372, &#39;h&#39;: 372}]


Metadata for real_00617.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 179, &#39;w&#39;: 359, &#39;h&#39;: 359}]


Metadata for real_00508.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 84, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00562.jpg:
[{&#39;x&#39;: 88, &#39;y&#39;: 118, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00610.jpg:
[{&#39;x&#39;: 37, &#39;y&#39;: 123, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00565.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 109, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00741.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 169, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00596.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 89, &#39;w&#39;: 432, &#39;h&#39;: 432}, {&#39;x&#39;: 231, &#39;y&#39;: 289, &#39;w&#39;: 128, &#39;h&#39;: 128}]


Metadata for real_00829.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 140, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00502.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 164, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00841.jpg:
[{&#39;x&#39;: 40, &#39;y&#39;: 95, &#39;w&#39;: 447, &#39;h&#39;: 447}]


Metadata for real_00517.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 113, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00716.jpg:
[{&#39;x&#39;: 278, &#39;y&#39;: 294, &#39;w&#39;: 95, &#39;h&#39;: 95}]


Metadata for real_00658.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 215, &#39;w&#39;: 377, &#39;h&#39;: 377}]


Metadata for real_00520.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 136, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00761.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 27, &#39;w&#39;: 493, &#39;h&#39;: 493}]


Metadata for real_00551.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 135, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00779.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 191, &#39;w&#39;: 370, &#39;h&#39;: 370}]


Metadata for real_00748.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 190, &#39;w&#39;: 349, &#39;h&#39;: 349}]


Metadata for real_00539.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 84, &#39;w&#39;: 453, &#39;h&#39;: 453}]


Metadata for real_00552.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 58, &#39;w&#39;: 451, &#39;h&#39;: 451}]


Metadata for real_00487.jpg:
[{&#39;x&#39;: 38, &#39;y&#39;: 74, &#39;w&#39;: 464, &#39;h&#39;: 464}]


Metadata for real_00482.jpg:
[{&#39;x&#39;: 11, &#39;y&#39;: 26, &#39;w&#39;: 501, &#39;h&#39;: 501}]


Metadata for real_00620.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 177, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00589.jpg:
[{&#39;x&#39;: 46, &#39;y&#39;: 440, &#39;w&#39;: 46, &#39;h&#39;: 46}]


Metadata for real_00547.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 170, &#39;w&#39;: 358, &#39;h&#39;: 358}]


Metadata for real_00622.jpg:
[{&#39;x&#39;: 45, &#39;y&#39;: 111, &#39;w&#39;: 476, &#39;h&#39;: 476}, {&#39;x&#39;: 99, &#39;y&#39;: 542, &#39;w&#39;: 52, &#39;h&#39;: 52}]


Metadata for real_00504.jpg:
[{&#39;x&#39;: 50, &#39;y&#39;: 100, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00556.jpg:
[{&#39;x&#39;: 67, &#39;y&#39;: 167, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00581.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 93, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00569.jpg:
[{&#39;x&#39;: 462, &#39;y&#39;: 208, &#39;w&#39;: 113, &#39;h&#39;: 113}]


Metadata for real_00615.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 117, &#39;w&#39;: 443, &#39;h&#39;: 443}]


Metadata for real_00582.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 203, &#39;w&#39;: 62, &#39;h&#39;: 62}]


Metadata for real_00603.jpg:
[{&#39;x&#39;: 13, &#39;y&#39;: 153, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00548.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 106, &#39;w&#39;: 463, &#39;h&#39;: 463}]


Metadata for real_00543.jpg:
[{&#39;x&#39;: 161, &#39;y&#39;: 515, &#39;w&#39;: 34, &#39;h&#39;: 34}]


Metadata for real_00500.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 107, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00549.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 152, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00492.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 93, &#39;w&#39;: 470, &#39;h&#39;: 470}]


Metadata for real_00584.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 145, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_00586.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 109, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_00583.jpg:
[{&#39;x&#39;: 195, &#39;y&#39;: 320, &#39;w&#39;: 80, &#39;h&#39;: 80}]


Metadata for real_00573.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 141, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00590.jpg:
[{&#39;x&#39;: 181, &#39;y&#39;: 178, &#39;w&#39;: 367, &#39;h&#39;: 367}]


Metadata for real_00554.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 152, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00618.jpg:
[{&#39;x&#39;: 54, &#39;y&#39;: 154, &#39;w&#39;: 383, &#39;h&#39;: 383}]


Metadata for real_00509.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 243, &#39;w&#39;: 337, &#39;h&#39;: 337}]


Metadata for real_00507.jpg:
[{&#39;x&#39;: 46, &#39;y&#39;: 85, &#39;w&#39;: 479, &#39;h&#39;: 479}]


Metadata for real_00578.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 81, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00540.jpg:
[{&#39;x&#39;: 121, &#39;y&#39;: 154, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00489.jpg:
[{&#39;x&#39;: 67, &#39;y&#39;: 189, &#39;w&#39;: 355, &#39;h&#39;: 355}]


Metadata for real_00501.jpg:
[{&#39;x&#39;: 9, &#39;y&#39;: 75, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00534.jpg:
[{&#39;x&#39;: 136, &#39;y&#39;: 221, &#39;w&#39;: 335, &#39;h&#39;: 335}]


Metadata for real_00513.jpg:
[{&#39;x&#39;: 408, &#39;y&#39;: 2, &#39;w&#39;: 107, &#39;h&#39;: 107}, {&#39;x&#39;: 315, &#39;y&#39;: 275, &#39;w&#39;: 189, &#39;h&#39;: 189}]


Metadata for real_00483.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 44, &#39;w&#39;: 497, &#39;h&#39;: 497}]


Metadata for real_00542.jpg:
[{&#39;x&#39;: 10, &#39;y&#39;: 244, &#39;w&#39;: 52, &#39;h&#39;: 52}, {&#39;x&#39;: 152, &#39;y&#39;: 146, &#39;w&#39;: 378, &#39;h&#39;: 378}]


Metadata for real_00579.jpg:
[{&#39;x&#39;: 57, &#39;y&#39;: 80, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00567.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 153, &#39;w&#39;: 393, &#39;h&#39;: 393}]


Metadata for real_00373.jpg:
[{&#39;x&#39;: 130, &#39;y&#39;: 169, &#39;w&#39;: 400, &#39;h&#39;: 400}]


Metadata for real_00357.jpg:
[{&#39;x&#39;: 126, &#39;y&#39;: 200, &#39;w&#39;: 354, &#39;h&#39;: 354}]


Metadata for real_00403.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 235, &#39;w&#39;: 349, &#39;h&#39;: 349}]


Metadata for real_00359.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 173, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_00476.jpg:
[{&#39;x&#39;: 142, &#39;y&#39;: 130, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00593.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 243, &#39;w&#39;: 91, &#39;h&#39;: 91}, {&#39;x&#39;: 388, &#39;y&#39;: 325, &#39;w&#39;: 123, &#39;h&#39;: 123}]


Metadata for real_00459.jpg:
[{&#39;x&#39;: 121, &#39;y&#39;: 206, &#39;w&#39;: 350, &#39;h&#39;: 350}]


Metadata for real_00386.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 75, &#39;w&#39;: 426, &#39;h&#39;: 426}]


Metadata for real_00417.jpg:
[{&#39;x&#39;: 151, &#39;y&#39;: 135, &#39;w&#39;: 203, &#39;h&#39;: 203}]


Metadata for real_00400.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 56, &#39;w&#39;: 453, &#39;h&#39;: 453}]


Metadata for real_00456.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 109, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00468.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 104, &#39;w&#39;: 434, &#39;h&#39;: 434}]


Metadata for real_00382.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 111, &#39;w&#39;: 413, &#39;h&#39;: 413}]


Metadata for real_00424.jpg:
[{&#39;x&#39;: 45, &#39;y&#39;: 73, &#39;w&#39;: 459, &#39;h&#39;: 459}]


Metadata for real_00456(1).jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 109, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00393.jpg:
[{&#39;x&#39;: 133, &#39;y&#39;: 169, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00404.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 165, &#39;w&#39;: 410, &#39;h&#39;: 410}]


Metadata for real_00425.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 139, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00391.jpg:
[{&#39;x&#39;: 104, &#39;y&#39;: 133, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00383.jpg:
[{&#39;x&#39;: 22, &#39;y&#39;: 59, &#39;w&#39;: 495, &#39;h&#39;: 495}]


Metadata for real_00439.jpg:
[{&#39;x&#39;: 33, &#39;y&#39;: 115, &#39;w&#39;: 385, &#39;h&#39;: 385}]


Metadata for real_00406.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 128, &#39;w&#39;: 378, &#39;h&#39;: 378}]


Metadata for real_00445.jpg:
[{&#39;x&#39;: 37, &#39;y&#39;: 87, &#39;w&#39;: 472, &#39;h&#39;: 472}]


Metadata for real_00464.jpg:
[{&#39;x&#39;: 132, &#39;y&#39;: 162, &#39;w&#39;: 349, &#39;h&#39;: 349}]


Metadata for real_00367.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 136, &#39;w&#39;: 424, &#39;h&#39;: 424}]


Metadata for real_00438.jpg:
[{&#39;x&#39;: 141, &#39;y&#39;: 125, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00358.jpg:
[{&#39;x&#39;: 461, &#39;y&#39;: 54, &#39;w&#39;: 100, &#39;h&#39;: 100}, {&#39;x&#39;: 126, &#39;y&#39;: 163, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00473.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 75, &#39;w&#39;: 446, &#39;h&#39;: 446}]


Metadata for real_00353.jpg:
[{&#39;x&#39;: 145, &#39;y&#39;: 197, &#39;w&#39;: 335, &#39;h&#39;: 335}]


Metadata for real_00385.jpg:
[{&#39;x&#39;: 505, &#39;y&#39;: 100, &#39;w&#39;: 61, &#39;h&#39;: 61}]


Metadata for real_00525.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 71, &#39;w&#39;: 449, &#39;h&#39;: 449}]


Metadata for real_00371.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 32, &#39;w&#39;: 439, &#39;h&#39;: 439}]


Metadata for real_00457.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 126, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00410.jpg:
[{&#39;x&#39;: 109, &#39;y&#39;: 70, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00333.jpg:
[{&#39;x&#39;: 28, &#39;y&#39;: 85, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_00392.jpg:
[{&#39;x&#39;: 132, &#39;y&#39;: 151, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_00429.jpg:
[{&#39;x&#39;: 55, &#39;y&#39;: 90, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00398.jpg:
[{&#39;x&#39;: 53, &#39;y&#39;: 90, &#39;w&#39;: 453, &#39;h&#39;: 453}]


Metadata for real_00377.jpg:
[{&#39;x&#39;: 109, &#39;y&#39;: 167, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00454.jpg:
[{&#39;x&#39;: 58, &#39;y&#39;: 91, &#39;w&#39;: 445, &#39;h&#39;: 445}]


Metadata for real_00331.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 126, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00381.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 89, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00376.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 172, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00444.jpg:
[{&#39;x&#39;: 25, &#39;y&#39;: 15, &#39;w&#39;: 503, &#39;h&#39;: 503}]


Metadata for real_00332.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 166, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_00414.jpg:
[{&#39;x&#39;: 170, &#39;y&#39;: 248, &#39;w&#39;: 329, &#39;h&#39;: 329}]


Metadata for real_00365.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 145, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00458.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 62, &#39;w&#39;: 479, &#39;h&#39;: 479}]


Metadata for real_00334.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 168, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_00408.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 59, &#39;w&#39;: 467, &#39;h&#39;: 467}]


Metadata for real_00348.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 68, &#39;w&#39;: 456, &#39;h&#39;: 456}]


Metadata for real_00356.jpg:
[{&#39;x&#39;: 43, &#39;y&#39;: 136, &#39;w&#39;: 442, &#39;h&#39;: 442}]


Metadata for real_00329.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 43, &#39;w&#39;: 478, &#39;h&#39;: 478}]


Metadata for real_00363.jpg:
[{&#39;x&#39;: 144, &#39;y&#39;: 189, &#39;w&#39;: 393, &#39;h&#39;: 393}]


Metadata for real_00430.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 124, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00481.jpg:
[{&#39;x&#39;: 58, &#39;y&#39;: 99, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00416.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 187, &#39;w&#39;: 348, &#39;h&#39;: 348}]


Metadata for real_00478.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 141, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00419.jpg:
[{&#39;x&#39;: 26, &#39;y&#39;: 39, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00355.jpg:
[{&#39;x&#39;: 107, &#39;y&#39;: 177, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00418.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 135, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00340.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 123, &#39;w&#39;: 425, &#39;h&#39;: 425}]


Metadata for real_00368.jpg:
[{&#39;x&#39;: 103, &#39;y&#39;: 144, &#39;w&#39;: 413, &#39;h&#39;: 413}]


Metadata for real_00460.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 92, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00345.jpg:
[{&#39;x&#39;: 137, &#39;y&#39;: 102, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_00465.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 192, &#39;w&#39;: 342, &#39;h&#39;: 342}]


Metadata for real_00331(1).jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 126, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00453.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 106, &#39;w&#39;: 461, &#39;h&#39;: 461}]


Metadata for real_00379.jpg:
[{&#39;x&#39;: 54, &#39;y&#39;: 153, &#39;w&#39;: 425, &#39;h&#39;: 425}]


Metadata for real_00370.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 139, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00390.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 65, &#39;w&#39;: 480, &#39;h&#39;: 480}]


Metadata for real_00412.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 117, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00470.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 86, &#39;w&#39;: 467, &#39;h&#39;: 467}]


Metadata for real_00462.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 210, &#39;w&#39;: 345, &#39;h&#39;: 345}]


Metadata for real_00387.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 120, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00434.jpg:
[{&#39;x&#39;: 120, &#39;y&#39;: 197, &#39;w&#39;: 347, &#39;h&#39;: 347}]


Metadata for real_00380.jpg:
[{&#39;x&#39;: 166, &#39;y&#39;: 149, &#39;w&#39;: 334, &#39;h&#39;: 334}]


Metadata for real_00461.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 51, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_00446.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 109, &#39;w&#39;: 434, &#39;h&#39;: 434}]


Metadata for real_00440.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 124, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00472.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 134, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00421.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 157, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00409.jpg:
[{&#39;x&#39;: 30, &#39;y&#39;: 117, &#39;w&#39;: 348, &#39;h&#39;: 348}]


Metadata for real_00450.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 135, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00452.jpg:
[{&#39;x&#39;: 45, &#39;y&#39;: 189, &#39;w&#39;: 244, &#39;h&#39;: 244}]


Metadata for real_00477.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 167, &#39;w&#39;: 382, &#39;h&#39;: 382}]


Metadata for real_00351.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 238, &#39;w&#39;: 357, &#39;h&#39;: 357}]


Metadata for real_00423.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 128, &#39;w&#39;: 73, &#39;h&#39;: 73}]


Metadata for real_00442.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 118, &#39;w&#39;: 423, &#39;h&#39;: 423}]


Metadata for real_00336.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 193, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00427.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 122, &#39;w&#39;: 460, &#39;h&#39;: 460}]


Metadata for real_00455.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 187, &#39;w&#39;: 387, &#39;h&#39;: 387}]


Metadata for real_00422.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 62, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00481(1).jpg:
[{&#39;x&#39;: 58, &#39;y&#39;: 99, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00388.jpg:
[{&#39;x&#39;: 42, &#39;y&#39;: 182, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00349.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 164, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00449.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 136, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00420.jpg:
[{&#39;x&#39;: 18, &#39;y&#39;: 157, &#39;w&#39;: 349, &#39;h&#39;: 349}]


Metadata for real_00378.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 166, &#39;w&#39;: 407, &#39;h&#39;: 407}]


Metadata for real_00346.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 56, &#39;w&#39;: 455, &#39;h&#39;: 455}]


Metadata for real_00413.jpg:
[{&#39;x&#39;: 6, &#39;y&#39;: 300, &#39;w&#39;: 54, &#39;h&#39;: 54}]


Metadata for real_00330.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 71, &#39;w&#39;: 474, &#39;h&#39;: 474}]


Metadata for real_00399.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 72, &#39;w&#39;: 445, &#39;h&#39;: 445}]


Metadata for real_00448.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 161, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00415.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 175, &#39;w&#39;: 368, &#39;h&#39;: 368}, {&#39;x&#39;: 20, &#39;y&#39;: 387, &#39;w&#39;: 56, &#39;h&#39;: 56}]


Metadata for real_00405.jpg:
[{&#39;x&#39;: 35, &#39;y&#39;: 124, &#39;w&#39;: 425, &#39;h&#39;: 425}, {&#39;x&#39;: 490, &#39;y&#39;: 292, &#39;w&#39;: 79, &#39;h&#39;: 79}]


Metadata for real_00362.jpg:
[{&#39;x&#39;: 223, &#39;y&#39;: 210, &#39;w&#39;: 295, &#39;h&#39;: 295}]


Metadata for real_00354.jpg:
[{&#39;x&#39;: 147, &#39;y&#39;: 143, &#39;w&#39;: 424, &#39;h&#39;: 424}, {&#39;x&#39;: 77, &#39;y&#39;: 343, &#39;w&#39;: 56, &#39;h&#39;: 56}]


Metadata for real_00343.jpg:
[{&#39;x&#39;: 57, &#39;y&#39;: 193, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_00432.jpg:
[{&#39;x&#39;: 63, &#39;y&#39;: 126, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_00474.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 179, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00467.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 171, &#39;w&#39;: 368, &#39;h&#39;: 368}]


Metadata for real_00397.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 153, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00475.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 166, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00480(1).jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 164, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00480.jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 164, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00436.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 124, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00441.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 67, &#39;w&#39;: 431, &#39;h&#39;: 431}]


Metadata for real_00401.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 84, &#39;w&#39;: 451, &#39;h&#39;: 451}]


Metadata for real_00469.jpg:
[{&#39;x&#39;: 128, &#39;y&#39;: 224, &#39;w&#39;: 343, &#39;h&#39;: 343}]


Metadata for real_00447.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 81, &#39;w&#39;: 477, &#39;h&#39;: 477}]


Metadata for real_00372.jpg:
[{&#39;x&#39;: 459, &#39;y&#39;: 27, &#39;w&#39;: 71, &#39;h&#39;: 71}, {&#39;x&#39;: 160, &#39;y&#39;: 151, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00407.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 103, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00361.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 81, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_00431.jpg:
[{&#39;x&#39;: 128, &#39;y&#39;: 127, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00451.jpg:
[{&#39;x&#39;: 138, &#39;y&#39;: 153, &#39;w&#39;: 358, &#39;h&#39;: 358}]


Metadata for real_00352.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 157, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00479.jpg:
[{&#39;x&#39;: 38, &#39;y&#39;: 13, &#39;w&#39;: 500, &#39;h&#39;: 500}, {&#39;x&#39;: 94, &#39;y&#39;: 90, &#39;w&#39;: 165, &#39;h&#39;: 165}]


Metadata for real_00395.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 97, &#39;w&#39;: 426, &#39;h&#39;: 426}]


Metadata for real_00312.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 213, &#39;w&#39;: 374, &#39;h&#39;: 374}]


Metadata for real_00299.jpg:
[{&#39;x&#39;: 30, &#39;y&#39;: 179, &#39;w&#39;: 381, &#39;h&#39;: 381}]


Metadata for real_00270.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 179, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_00268.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 147, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00310.jpg:
[{&#39;x&#39;: 23, &#39;y&#39;: 138, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00236.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 77, &#39;w&#39;: 485, &#39;h&#39;: 485}]


Metadata for real_00186.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 100, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_00294.jpg:
[{&#39;x&#39;: 128, &#39;y&#39;: 164, &#39;w&#39;: 388, &#39;h&#39;: 388}]


Metadata for real_00185.jpg:
[{&#39;x&#39;: 107, &#39;y&#39;: 168, &#39;w&#39;: 381, &#39;h&#39;: 381}]


Metadata for real_00305.jpg:
[{&#39;x&#39;: 494, &#39;y&#39;: 51, &#39;w&#39;: 66, &#39;h&#39;: 66}, {&#39;x&#39;: 134, &#39;y&#39;: 176, &#39;w&#39;: 373, &#39;h&#39;: 373}]


Metadata for real_00328.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 97, &#39;w&#39;: 476, &#39;h&#39;: 476}]


Metadata for real_00235.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 127, &#39;w&#39;: 434, &#39;h&#39;: 434}]


Metadata for real_00550.jpg:
[{&#39;x&#39;: 32, &#39;y&#39;: 69, &#39;w&#39;: 492, &#39;h&#39;: 492}]


Metadata for real_00396.jpg:
[{&#39;x&#39;: 101, &#39;y&#39;: 168, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00531.jpg:
[{&#39;x&#39;: 116, &#39;y&#39;: 156, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00296.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 175, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00195.jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 159, &#39;w&#39;: 335, &#39;h&#39;: 335}]


Metadata for real_00281.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 160, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00221.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 139, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00172.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 135, &#39;w&#39;: 400, &#39;h&#39;: 400}]


Metadata for real_00273.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 145, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00225.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 186, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00189.jpg:
[{&#39;x&#39;: 142, &#39;y&#39;: 153, &#39;w&#39;: 371, &#39;h&#39;: 371}]


Metadata for real_00262.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 83, &#39;w&#39;: 52, &#39;h&#39;: 52}, {&#39;x&#39;: 107, &#39;y&#39;: 173, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_00291.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 149, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_00196.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 138, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00263.jpg:
[{&#39;x&#39;: 91, &#39;y&#39;: 172, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00277.jpg:
[{&#39;x&#39;: 116, &#39;y&#39;: 187, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00188.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 125, &#39;w&#39;: 410, &#39;h&#39;: 410}]


Metadata for real_00182.jpg:
[{&#39;x&#39;: 120, &#39;y&#39;: 205, &#39;w&#39;: 358, &#39;h&#39;: 358}]


Metadata for real_00220.jpg:
[{&#39;x&#39;: 37, &#39;y&#39;: 156, &#39;w&#39;: 399, &#39;h&#39;: 399}]


Metadata for real_00212.jpg:
[{&#39;x&#39;: 24, &#39;y&#39;: 207, &#39;w&#39;: 72, &#39;h&#39;: 72}]


Metadata for real_00183.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 137, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00184.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 204, &#39;w&#39;: 373, &#39;h&#39;: 373}]


Metadata for real_00283.jpg:
[{&#39;x&#39;: 45, &#39;y&#39;: 132, &#39;w&#39;: 423, &#39;h&#39;: 423}]


Metadata for real_00229.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 161, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00206.jpg:
[{&#39;x&#39;: 57, &#39;y&#39;: 140, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00208.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 123, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00337.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 132, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00230.jpg:
[{&#39;x&#39;: 120, &#39;y&#39;: 210, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00271.jpg:
[{&#39;x&#39;: 54, &#39;y&#39;: 95, &#39;w&#39;: 459, &#39;h&#39;: 459}]


Metadata for real_00209.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 200, &#39;w&#39;: 362, &#39;h&#39;: 362}]


Metadata for real_00238.jpg:
[{&#39;x&#39;: 18, &#39;y&#39;: 26, &#39;w&#39;: 520, &#39;h&#39;: 520}]


Metadata for real_00222.jpg:
[{&#39;x&#39;: 158, &#39;y&#39;: 312, &#39;w&#39;: 245, &#39;h&#39;: 245}]


Metadata for real_00242.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 159, &#39;w&#39;: 379, &#39;h&#39;: 379}]


Metadata for real_00207.jpg:
[{&#39;x&#39;: 41, &#39;y&#39;: 140, &#39;w&#39;: 406, &#39;h&#39;: 406}]


Metadata for real_00216.jpg:
[{&#39;x&#39;: 101, &#39;y&#39;: 168, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00200.jpg:
[{&#39;x&#39;: 101, &#39;y&#39;: 37, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00344.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 41, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00295.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 99, &#39;w&#39;: 442, &#39;h&#39;: 442}]


Metadata for real_00306.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 199, &#39;w&#39;: 350, &#39;h&#39;: 350}]


Metadata for real_00241.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 120, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00218.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 19, &#39;w&#39;: 478, &#39;h&#39;: 478}]


Metadata for real_00315.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 200, &#39;w&#39;: 381, &#39;h&#39;: 381}]


Metadata for real_00233.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 119, &#39;w&#39;: 429, &#39;h&#39;: 429}]


Metadata for real_00239.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 180, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00234.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 105, &#39;w&#39;: 410, &#39;h&#39;: 410}]


Metadata for real_00174.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 102, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00255.jpg:
[{&#39;x&#39;: 378, &#39;y&#39;: 224, &#39;w&#39;: 100, &#39;h&#39;: 100}]


Metadata for real_00278.jpg:
[{&#39;x&#39;: 97, &#39;y&#39;: 191, &#39;w&#39;: 363, &#39;h&#39;: 363}]


Metadata for real_00204.jpg:
[{&#39;x&#39;: 35, &#39;y&#39;: 33, &#39;w&#39;: 489, &#39;h&#39;: 489}]


Metadata for real_00254.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 189, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00245.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 135, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00219.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 349, &#39;w&#39;: 104, &#39;h&#39;: 104}, {&#39;x&#39;: 535, &#39;y&#39;: 437, &#39;w&#39;: 60, &#39;h&#39;: 60}]


Metadata for real_00321.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 70, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00227.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 120, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00303.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 188, &#39;w&#39;: 370, &#39;h&#39;: 370}]


Metadata for real_00261.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 190, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00179.jpg:
[{&#39;x&#39;: 209, &#39;y&#39;: 186, &#39;w&#39;: 357, &#39;h&#39;: 357}]


Metadata for real_00180.jpg:
[{&#39;x&#39;: 116, &#39;y&#39;: 199, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00317.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 180, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00181.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 161, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00177.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 220, &#39;w&#39;: 100, &#39;h&#39;: 100}, {&#39;x&#39;: 35, &#39;y&#39;: 284, &#39;w&#39;: 257, &#39;h&#39;: 257}]


Metadata for real_00304.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 8, &#39;w&#39;: 49, &#39;h&#39;: 49}, {&#39;x&#39;: 70, &#39;y&#39;: 103, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_00194.jpg:
[{&#39;x&#39;: 57, &#39;y&#39;: 142, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00276.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 187, &#39;w&#39;: 337, &#39;h&#39;: 337}]


Metadata for real_00289.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 168, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00264.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 121, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00258.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 58, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00244.jpg:
[{&#39;x&#39;: 103, &#39;y&#39;: 137, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00175.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 116, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00213.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 93, &#39;w&#39;: 455, &#39;h&#39;: 455}]


Metadata for real_00279.jpg:
[{&#39;x&#39;: 153, &#39;y&#39;: 211, &#39;w&#39;: 371, &#39;h&#39;: 371}]


Metadata for real_00205.jpg:
[{&#39;x&#39;: 99, &#39;y&#39;: 203, &#39;w&#39;: 364, &#39;h&#39;: 364}]


Metadata for real_00192.jpg:
[{&#39;x&#39;: 25, &#39;y&#39;: 174, &#39;w&#39;: 413, &#39;h&#39;: 413}]


Metadata for real_00290.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 110, &#39;w&#39;: 448, &#39;h&#39;: 448}]


Metadata for real_00226.jpg:
[{&#39;x&#39;: 104, &#39;y&#39;: 89, &#39;w&#39;: 443, &#39;h&#39;: 443}]


Metadata for real_00190.jpg:
[{&#39;x&#39;: 34, &#39;y&#39;: 68, &#39;w&#39;: 448, &#39;h&#39;: 448}]


Metadata for real_00286.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 197, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_00252.jpg:
[{&#39;x&#39;: 110, &#39;y&#39;: 161, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00274.jpg:
[{&#39;x&#39;: 80, &#39;y&#39;: 156, &#39;w&#39;: 426, &#39;h&#39;: 426}]


Metadata for real_00285.jpg:
[{&#39;x&#39;: 34, &#39;y&#39;: 99, &#39;w&#39;: 468, &#39;h&#39;: 468}]


Metadata for real_00260.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 123, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_00249.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 120, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00203.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 5, &#39;w&#39;: 469, &#39;h&#39;: 469}]


Metadata for real_00265.jpg:
[{&#39;x&#39;: 67, &#39;y&#39;: 75, &#39;w&#39;: 459, &#39;h&#39;: 459}]


Metadata for real_00314.jpg:
[{&#39;x&#39;: 126, &#39;y&#39;: 241, &#39;w&#39;: 238, &#39;h&#39;: 238}]


Metadata for real_00313.jpg:
[{&#39;x&#39;: 80, &#39;y&#39;: 108, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00232.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 96, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00267.jpg:
[{&#39;x&#39;: 159, &#39;y&#39;: 197, &#39;w&#39;: 359, &#39;h&#39;: 359}]


Metadata for real_00292.jpg:
[{&#39;x&#39;: 189, &#39;y&#39;: 214, &#39;w&#39;: 350, &#39;h&#39;: 350}]


Metadata for real_00173.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 145, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_00301.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 188, &#39;w&#39;: 365, &#39;h&#39;: 365}]


Metadata for real_00266.jpg:
[{&#39;x&#39;: 16, &#39;y&#39;: 144, &#39;w&#39;: 400, &#39;h&#39;: 400}]


Metadata for real_00248.jpg:
[{&#39;x&#39;: 129, &#39;y&#39;: 180, &#39;w&#39;: 362, &#39;h&#39;: 362}]


Metadata for real_00308.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 162, &#39;w&#39;: 77, &#39;h&#39;: 77}]


Metadata for real_00293.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 113, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00272.jpg:
[{&#39;x&#39;: 27, &#39;y&#39;: 51, &#39;w&#39;: 477, &#39;h&#39;: 477}]


Metadata for real_00243.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 156, &#39;w&#39;: 366, &#39;h&#39;: 366}]


Metadata for real_00324.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 103, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00210.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 120, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_00322.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 209, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00307.jpg:
[{&#39;x&#39;: 43, &#39;y&#39;: 98, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00201.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 52, &#39;w&#39;: 489, &#39;h&#39;: 489}]


Metadata for real_00325.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 161, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00231.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 172, &#39;w&#39;: 337, &#39;h&#39;: 337}]


Metadata for real_00298.jpg:
[{&#39;x&#39;: 103, &#39;y&#39;: 207, &#39;w&#39;: 350, &#39;h&#39;: 350}]


Metadata for real_00257.jpg:
[{&#39;x&#39;: 87, &#39;y&#39;: 109, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00251.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 140, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00237.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 54, &#39;w&#39;: 497, &#39;h&#39;: 497}]


Metadata for real_00284.jpg:
[{&#39;x&#39;: 28, &#39;y&#39;: 166, &#39;w&#39;: 409, &#39;h&#39;: 409}]


Metadata for real_00191.jpg:
[{&#39;x&#39;: 314, &#39;y&#39;: 448, &#39;w&#39;: 68, &#39;h&#39;: 68}]


Metadata for real_00287.jpg:
[{&#39;x&#39;: 156, &#39;y&#39;: 174, &#39;w&#39;: 397, &#39;h&#39;: 397}]


Metadata for real_00297.jpg:
[{&#39;x&#39;: 109, &#39;y&#39;: 198, &#39;w&#39;: 366, &#39;h&#39;: 366}]


Metadata for real_00246.jpg:
[{&#39;x&#39;: 33, &#39;y&#39;: 105, &#39;w&#39;: 433, &#39;h&#39;: 433}]


Metadata for real_00311.jpg:
[{&#39;x&#39;: 48, &#39;y&#39;: 133, &#39;w&#39;: 429, &#39;h&#39;: 429}]


Metadata for real_00197.jpg:
[{&#39;x&#39;: 48, &#39;y&#39;: 211, &#39;w&#39;: 358, &#39;h&#39;: 358}]


Metadata for real_00214.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 135, &#39;w&#39;: 434, &#39;h&#39;: 434}]


Metadata for real_00211.jpg:
[{&#39;x&#39;: 154, &#39;y&#39;: 137, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00256.jpg:
[{&#39;x&#39;: 120, &#39;y&#39;: 146, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00178.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 51, &#39;w&#39;: 484, &#39;h&#39;: 484}]


Metadata for real_00133.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 25, &#39;w&#39;: 482, &#39;h&#39;: 482}]


Metadata for real_00187.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 28, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00115.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 124, &#39;w&#39;: 413, &#39;h&#39;: 413}]


Metadata for real_00176.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 161, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00121.jpg:
[{&#39;x&#39;: 58, &#39;y&#39;: 113, &#39;w&#39;: 454, &#39;h&#39;: 454}]


Metadata for real_00041.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 79, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00024.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 60, &#39;w&#39;: 503, &#39;h&#39;: 503}]


Metadata for real_00114.jpg:
[{&#39;x&#39;: 53, &#39;y&#39;: 108, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00169.jpg:
[{&#39;x&#39;: 169, &#39;y&#39;: 181, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00048.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 134, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00163.jpg:
[{&#39;x&#39;: 32, &#39;y&#39;: 131, &#39;w&#39;: 427, &#39;h&#39;: 427}]


Metadata for real_00035.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 175, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00151.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 117, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00122.jpg:
[{&#39;x&#39;: 30, &#39;y&#39;: 71, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00050.jpg:
[{&#39;x&#39;: 186, &#39;y&#39;: 146, &#39;w&#39;: 363, &#39;h&#39;: 363}]


Metadata for real_00071.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 162, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00127.jpg:
[{&#39;x&#39;: 97, &#39;y&#39;: 174, &#39;w&#39;: 351, &#39;h&#39;: 351}]


Metadata for real_00092.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 189, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00040.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 163, &#39;w&#39;: 305, &#39;h&#39;: 305}]


Metadata for real_00049.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 179, &#39;w&#39;: 383, &#39;h&#39;: 383}]


Metadata for real_00119.jpg:
[{&#39;x&#39;: 171, &#39;y&#39;: 100, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00075.jpg:
[{&#39;x&#39;: 29, &#39;y&#39;: 112, &#39;w&#39;: 429, &#39;h&#39;: 429}]


Metadata for real_00079.jpg:
[{&#39;x&#39;: 40, &#39;y&#39;: 138, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00167.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 167, &#39;w&#39;: 390, &#39;h&#39;: 390}]


Metadata for real_00103.jpg:
[{&#39;x&#39;: 301, &#39;y&#39;: 121, &#39;w&#39;: 60, &#39;h&#39;: 60}]


Metadata for real_00120.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 99, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_00069.jpg:
[{&#39;x&#39;: 33, &#39;y&#39;: 83, &#39;w&#39;: 504, &#39;h&#39;: 504}]


Metadata for real_00171.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 102, &#39;w&#39;: 439, &#39;h&#39;: 439}]


Metadata for real_00104.jpg:
[{&#39;x&#39;: 28, &#39;y&#39;: 1, &#39;w&#39;: 55, &#39;h&#39;: 55}, {&#39;x&#39;: 138, &#39;y&#39;: 186, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00067.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 83, &#39;w&#39;: 460, &#39;h&#39;: 460}]


Metadata for real_00302.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 143, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_00074.jpg:
[{&#39;x&#39;: 148, &#39;y&#39;: 148, &#39;w&#39;: 425, &#39;h&#39;: 425}]


Metadata for real_00038.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 165, &#39;w&#39;: 379, &#39;h&#39;: 379}]


Metadata for real_00112.jpg:
[{&#39;x&#39;: 167, &#39;y&#39;: 139, &#39;w&#39;: 367, &#39;h&#39;: 367}]


Metadata for real_00060.jpg:
[{&#39;x&#39;: 80, &#39;y&#39;: 19, &#39;w&#39;: 474, &#39;h&#39;: 474}]


Metadata for real_00052.jpg:
[{&#39;x&#39;: 107, &#39;y&#39;: 205, &#39;w&#39;: 363, &#39;h&#39;: 363}]


Metadata for real_00139.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 128, &#39;w&#39;: 446, &#39;h&#39;: 446}]


Metadata for real_00144.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 93, &#39;w&#39;: 450, &#39;h&#39;: 450}]


Metadata for real_00129.jpg:
[{&#39;x&#39;: 26, &#39;y&#39;: 33, &#39;w&#39;: 471, &#39;h&#39;: 471}]


Metadata for real_00113.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 108, &#39;w&#39;: 476, &#39;h&#39;: 476}]


Metadata for real_00027.jpg:
[{&#39;x&#39;: 28, &#39;y&#39;: 60, &#39;w&#39;: 501, &#39;h&#39;: 501}]


Metadata for real_00078.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 107, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_00036.jpg:
[{&#39;x&#39;: 222, &#39;y&#39;: 204, &#39;w&#39;: 279, &#39;h&#39;: 279}]


Metadata for real_00032.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 169, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00090.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 77, &#39;w&#39;: 480, &#39;h&#39;: 480}]


Metadata for real_00152.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 164, &#39;w&#39;: 381, &#39;h&#39;: 381}]


Metadata for real_00156.jpg:
[{&#39;x&#39;: 167, &#39;y&#39;: 188, &#39;w&#39;: 378, &#39;h&#39;: 378}]


Metadata for real_00138.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 109, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00165.jpg:
[{&#39;x&#39;: 197, &#39;y&#39;: 95, &#39;w&#39;: 388, &#39;h&#39;: 388}, {&#39;x&#39;: 29, &#39;y&#39;: 196, &#39;w&#39;: 160, &#39;h&#39;: 160}]


Metadata for real_00160.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 177, &#39;w&#39;: 368, &#39;h&#39;: 368}]


Metadata for real_00087.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 206, &#39;w&#39;: 349, &#39;h&#39;: 349}]


Metadata for real_00051.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 176, &#39;w&#39;: 337, &#39;h&#39;: 337}]


Metadata for real_00058.jpg:
[{&#39;x&#39;: 43, &#39;y&#39;: 46, &#39;w&#39;: 517, &#39;h&#39;: 517}]


Metadata for real_00089.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 185, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00030.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 170, &#39;w&#39;: 387, &#39;h&#39;: 387}]


Metadata for real_00026.jpg:
[{&#39;x&#39;: 17, &#39;y&#39;: 84, &#39;w&#39;: 466, &#39;h&#39;: 466}, {&#39;x&#39;: 121, &#39;y&#39;: 358, &#39;w&#39;: 130, &#39;h&#39;: 130}]


Metadata for real_00068.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 154, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_00053.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 148, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00170.jpg:
[{&#39;x&#39;: 53, &#39;y&#39;: 131, &#39;w&#39;: 446, &#39;h&#39;: 446}]


Metadata for real_00108.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 147, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00300.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 177, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00168.jpg:
[{&#39;x&#39;: 116, &#39;y&#39;: 178, &#39;w&#39;: 376, &#39;h&#39;: 376}]


Metadata for real_00154.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 152, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00102.jpg:
[{&#39;x&#39;: 86, &#39;y&#39;: 112, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00084.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 99, &#39;w&#39;: 473, &#39;h&#39;: 473}]


Metadata for real_00158.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 102, &#39;w&#39;: 472, &#39;h&#39;: 472}]


Metadata for real_00140.jpg:
[{&#39;x&#39;: 94, &#39;y&#39;: 164, &#39;w&#39;: 399, &#39;h&#39;: 399}]


Metadata for real_00161.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 240, &#39;w&#39;: 116, &#39;h&#39;: 116}]


Metadata for real_00023.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 42, &#39;w&#39;: 481, &#39;h&#39;: 481}]


Metadata for real_00033.jpg:
[{&#39;x&#39;: 59, &#39;y&#39;: 50, &#39;w&#39;: 483, &#39;h&#39;: 483}]


Metadata for real_00145.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 120, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00094.jpg:
[{&#39;x&#39;: 22, &#39;y&#39;: 41, &#39;w&#39;: 538, &#39;h&#39;: 538}]


Metadata for real_00111.jpg:
[{&#39;x&#39;: 35, &#39;y&#39;: 177, &#39;w&#39;: 344, &#39;h&#39;: 344}]


Metadata for real_00150.jpg:
[{&#39;x&#39;: 42, &#39;y&#39;: 87, &#39;w&#39;: 484, &#39;h&#39;: 484}]


Metadata for real_00132.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 92, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00088.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 129, &#39;w&#39;: 447, &#39;h&#39;: 447}]


Metadata for real_00123.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 154, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00031.jpg:
[{&#39;x&#39;: 12, &#39;y&#39;: 159, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00137.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 125, &#39;w&#39;: 443, &#39;h&#39;: 443}]


Metadata for real_00062.jpg:
[{&#39;x&#39;: 141, &#39;y&#39;: 188, &#39;w&#39;: 378, &#39;h&#39;: 378}]


Metadata for real_00141.jpg:
[{&#39;x&#39;: 86, &#39;y&#39;: 134, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00085.jpg:
[{&#39;x&#39;: 48, &#39;y&#39;: 59, &#39;w&#39;: 470, &#39;h&#39;: 470}]


Metadata for real_00059.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 139, &#39;w&#39;: 424, &#39;h&#39;: 424}]


Metadata for real_00100.jpg:
[{&#39;x&#39;: 24, &#39;y&#39;: 92, &#39;w&#39;: 469, &#39;h&#39;: 469}]


Metadata for real_00437.jpg:
[{&#39;x&#39;: 64, &#39;y&#39;: 93, &#39;w&#39;: 449, &#39;h&#39;: 449}]


Metadata for real_00054.jpg:
[{&#39;x&#39;: 127, &#39;y&#39;: 131, &#39;w&#39;: 421, &#39;h&#39;: 421}]


Metadata for real_00149.jpg:
[{&#39;x&#39;: 72, &#39;y&#39;: 190, &#39;w&#39;: 299, &#39;h&#39;: 299}]


Metadata for real_00076.jpg:
[{&#39;x&#39;: 67, &#39;y&#39;: 56, &#39;w&#39;: 461, &#39;h&#39;: 461}]


Metadata for real_00117.jpg:
[{&#39;x&#39;: 158, &#39;y&#39;: 188, &#39;w&#39;: 346, &#39;h&#39;: 346}]


Metadata for real_00095.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 142, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00065.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 125, &#39;w&#39;: 431, &#39;h&#39;: 431}]


Metadata for real_00130.jpg:
[{&#39;x&#39;: 105, &#39;y&#39;: 113, &#39;w&#39;: 387, &#39;h&#39;: 387}]


Metadata for real_00126.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 135, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00082.jpg:
[{&#39;x&#39;: 63, &#39;y&#39;: 88, &#39;w&#39;: 479, &#39;h&#39;: 479}]


Metadata for real_00101.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 69, &#39;w&#39;: 477, &#39;h&#39;: 477}]


Metadata for real_00073.jpg:
[{&#39;x&#39;: 38, &#39;y&#39;: 154, &#39;w&#39;: 416, &#39;h&#39;: 416}]


Metadata for real_00063.jpg:
[{&#39;x&#39;: 12, &#39;y&#39;: 65, &#39;w&#39;: 465, &#39;h&#39;: 465}]


Metadata for real_00128.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 24, &#39;w&#39;: 510, &#39;h&#39;: 510}]


Metadata for real_00025.jpg:
[{&#39;x&#39;: 91, &#39;y&#39;: 121, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_00083.jpg:
[{&#39;x&#39;: 126, &#39;y&#39;: 241, &#39;w&#39;: 343, &#39;h&#39;: 343}]


Metadata for real_00045.jpg:
[{&#39;x&#39;: 161, &#39;y&#39;: 141, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00164.jpg:
[{&#39;x&#39;: 88, &#39;y&#39;: 125, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00116.jpg:
[{&#39;x&#39;: 132, &#39;y&#39;: 159, &#39;w&#39;: 372, &#39;h&#39;: 372}]


Metadata for real_00107.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 156, &#39;w&#39;: 388, &#39;h&#39;: 388}]


Metadata for real_00143.jpg:
[{&#39;x&#39;: 178, &#39;y&#39;: 143, &#39;w&#39;: 348, &#39;h&#39;: 348}]


Metadata for real_00096.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 131, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00055.jpg:
[{&#39;x&#39;: 201, &#39;y&#39;: 301, &#39;w&#39;: 106, &#39;h&#39;: 106}, {&#39;x&#39;: 496, &#39;y&#39;: 475, &#39;w&#39;: 70, &#39;h&#39;: 70}]


Metadata for real_00109.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 55, &#39;w&#39;: 505, &#39;h&#39;: 505}]


Metadata for real_00153.jpg:
[{&#39;x&#39;: 118, &#39;y&#39;: 373, &#39;w&#39;: 94, &#39;h&#39;: 94}]


Metadata for real_00157.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 58, &#39;w&#39;: 454, &#39;h&#39;: 454}]


Metadata for real_00136.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 112, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00046.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 133, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00142.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 110, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00037.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 82, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00106.jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 67, &#39;w&#39;: 477, &#39;h&#39;: 477}]


Metadata for real_00135.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 193, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00044.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 123, &#39;w&#39;: 420, &#39;h&#39;: 420}]


Metadata for real_00043.jpg:
[{&#39;x&#39;: 142, &#39;y&#39;: 119, &#39;w&#39;: 439, &#39;h&#39;: 439}]


Metadata for real_00253.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 25, &#39;w&#39;: 456, &#39;h&#39;: 456}]


Metadata for real_00124.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 164, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00061.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 32, &#39;w&#39;: 485, &#39;h&#39;: 485}]


Metadata for real_00411.jpg:
[{&#39;x&#39;: 90, &#39;y&#39;: 136, &#39;w&#39;: 410, &#39;h&#39;: 410}]


Metadata for real_00360.jpg:
[{&#39;x&#39;: 63, &#39;y&#39;: 105, &#39;w&#39;: 442, &#39;h&#39;: 442}]


Metadata for real_00028.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 84, &#39;w&#39;: 440, &#39;h&#39;: 440}]


Metadata for real_00093.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 152, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00110.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 121, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00159.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 102, &#39;w&#39;: 434, &#39;h&#39;: 434}]


Metadata for real_00047.jpg:
[{&#39;x&#39;: 124, &#39;y&#39;: 105, &#39;w&#39;: 418, &#39;h&#39;: 418}, {&#39;x&#39;: 100, &#39;y&#39;: 477, &#39;w&#39;: 73, &#39;h&#39;: 73}]


Metadata for real_00080.jpg:
[{&#39;x&#39;: 131, &#39;y&#39;: 129, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_00006.jpg:
[{&#39;x&#39;: 61, &#39;y&#39;: 62, &#39;w&#39;: 472, &#39;h&#39;: 472}]


Metadata for real_00011.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 120, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_00002.jpg:
[{&#39;x&#39;: 80, &#39;y&#39;: 140, &#39;w&#39;: 436, &#39;h&#39;: 436}]


Metadata for real_00008.jpg:
[{&#39;x&#39;: 253, &#39;y&#39;: 217, &#39;w&#39;: 245, &#39;h&#39;: 245}, {&#39;x&#39;: 328, &#39;y&#39;: 432, &#39;w&#39;: 83, &#39;h&#39;: 83}]


Metadata for real_00015.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 92, &#39;w&#39;: 455, &#39;h&#39;: 455}]


Metadata for real_00019.jpg:
[{&#39;x&#39;: 94, &#39;y&#39;: 212, &#39;w&#39;: 354, &#39;h&#39;: 354}]


Metadata for real_00004.jpg:
[{&#39;x&#39;: 134, &#39;y&#39;: 173, &#39;w&#39;: 356, &#39;h&#39;: 356}]


Metadata for real_00003.jpg:
[{&#39;x&#39;: 33, &#39;y&#39;: 121, &#39;w&#39;: 362, &#39;h&#39;: 362}]


Metadata for real_00017.jpg:
[{&#39;x&#39;: 84, &#39;y&#39;: 125, &#39;w&#39;: 447, &#39;h&#39;: 447}]


Metadata for real_00014.jpg:
[{&#39;x&#39;: 75, &#39;y&#39;: 108, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00022.jpg:
[{&#39;x&#39;: 43, &#39;y&#39;: 46, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00012.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 188, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00010.jpg:
[{&#39;x&#39;: 17, &#39;y&#39;: 84, &#39;w&#39;: 448, &#39;h&#39;: 448}]


Metadata for real_00001.jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 140, &#39;w&#39;: 428, &#39;h&#39;: 428}]


Metadata for real_00131.jpg:
[{&#39;x&#39;: 120, &#39;y&#39;: 179, &#39;w&#39;: 374, &#39;h&#39;: 374}]


Metadata for real_00394.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 103, &#39;w&#39;: 452, &#39;h&#39;: 452}]


Metadata for real_00125.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 131, &#39;w&#39;: 397, &#39;h&#39;: 397}]


Metadata for real_00134.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 95, &#39;w&#39;: 459, &#39;h&#39;: 459}]


Metadata for real_00166.jpg:
[{&#39;x&#39;: 120, &#39;y&#39;: 169, &#39;w&#39;: 363, &#39;h&#39;: 363}]


Metadata for real_00947.jpg:
[{&#39;x&#39;: 522, &#39;y&#39;: 138, &#39;w&#39;: 66, &#39;h&#39;: 66}]


Metadata for real_01042.jpg:
[{&#39;x&#39;: 45, &#39;y&#39;: 136, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_01053.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 50, &#39;w&#39;: 471, &#39;h&#39;: 471}]


Metadata for real_01057.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 156, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00964.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 113, &#39;w&#39;: 451, &#39;h&#39;: 451}]


Metadata for real_00956.jpg:
[{&#39;x&#39;: 186, &#39;y&#39;: 170, &#39;w&#39;: 360, &#39;h&#39;: 360}]


Metadata for real_01067.jpg:
[{&#39;x&#39;: 208, &#39;y&#39;: 165, &#39;w&#39;: 346, &#39;h&#39;: 346}]


Metadata for real_01044.jpg:
[{&#39;x&#39;: 167, &#39;y&#39;: 162, &#39;w&#39;: 380, &#39;h&#39;: 380}]


Metadata for real_00975.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 103, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_01041.jpg:
[{&#39;x&#39;: 139, &#39;y&#39;: 122, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00945.jpg:
[{&#39;x&#39;: 54, &#39;y&#39;: 87, &#39;w&#39;: 466, &#39;h&#39;: 466}]


Metadata for real_01021.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 97, &#39;w&#39;: 457, &#39;h&#39;: 457}]


Metadata for real_01062.jpg:
[{&#39;x&#39;: 34, &#39;y&#39;: 159, &#39;w&#39;: 359, &#39;h&#39;: 359}]


Metadata for real_01068.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 164, &#39;w&#39;: 382, &#39;h&#39;: 382}]


Metadata for real_01065.jpg:
[{&#39;x&#39;: 107, &#39;y&#39;: 178, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_01027.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 86, &#39;w&#39;: 438, &#39;h&#39;: 438}]


Metadata for real_01016.jpg:
[{&#39;x&#39;: 82, &#39;y&#39;: 115, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00961.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 165, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_01010.jpg:
[{&#39;x&#39;: 34, &#39;y&#39;: 107, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_00981.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 171, &#39;w&#39;: 394, &#39;h&#39;: 394}]


Metadata for real_00995.jpg:
[{&#39;x&#39;: 15, &#39;y&#39;: 71, &#39;w&#39;: 455, &#39;h&#39;: 455}]


Metadata for real_01050.jpg:
[{&#39;x&#39;: 174, &#39;y&#39;: 181, &#39;w&#39;: 356, &#39;h&#39;: 356}]


Metadata for real_01056.jpg:
[{&#39;x&#39;: 118, &#39;y&#39;: 150, &#39;w&#39;: 375, &#39;h&#39;: 375}]


Metadata for real_00977.jpg:
[{&#39;x&#39;: 88, &#39;y&#39;: 52, &#39;w&#39;: 432, &#39;h&#39;: 432}, {&#39;x&#39;: 428, &#39;y&#39;: 484, &#39;w&#39;: 110, &#39;h&#39;: 110}]


Metadata for real_00985.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 114, &#39;w&#39;: 442, &#39;h&#39;: 442}]


Metadata for real_01031.jpg:
[{&#39;x&#39;: 138, &#39;y&#39;: 166, &#39;w&#39;: 373, &#39;h&#39;: 373}]


Metadata for real_01073.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 150, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_01008.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 179, &#39;w&#39;: 368, &#39;h&#39;: 368}]


Metadata for real_00978.jpg:
[{&#39;x&#39;: 40, &#39;y&#39;: 71, &#39;w&#39;: 483, &#39;h&#39;: 483}]


Metadata for real_01077.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 167, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_01032.jpg:
[{&#39;x&#39;: 35, &#39;y&#39;: 28, &#39;w&#39;: 473, &#39;h&#39;: 473}]


Metadata for real_00943.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 194, &#39;w&#39;: 388, &#39;h&#39;: 388}]


Metadata for real_01015.jpg:
[{&#39;x&#39;: 78, &#39;y&#39;: 96, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_01037.jpg:
[{&#39;x&#39;: 160, &#39;y&#39;: 178, &#39;w&#39;: 350, &#39;h&#39;: 350}]


Metadata for real_01080.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 87, &#39;w&#39;: 447, &#39;h&#39;: 447}]


Metadata for real_00954.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 8, &#39;w&#39;: 508, &#39;h&#39;: 508}]


Metadata for real_00967.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 118, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_01006.jpg:
[{&#39;x&#39;: 53, &#39;y&#39;: 120, &#39;w&#39;: 431, &#39;h&#39;: 431}]


Metadata for real_01039.jpg:
[{&#39;x&#39;: 163, &#39;y&#39;: 123, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_01017.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 95, &#39;w&#39;: 436, &#39;h&#39;: 436}]


Metadata for real_01075.jpg:
[{&#39;x&#39;: 100, &#39;y&#39;: 159, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_01079.jpg:
[{&#39;x&#39;: 69, &#39;y&#39;: 67, &#39;w&#39;: 475, &#39;h&#39;: 475}]


Metadata for real_01049.jpg:
[{&#39;x&#39;: 159, &#39;y&#39;: 212, &#39;w&#39;: 343, &#39;h&#39;: 343}]


Metadata for real_01040.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 134, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_00958.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 185, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00944.jpg:
[{&#39;x&#39;: 23, &#39;y&#39;: 147, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_01061.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 186, &#39;w&#39;: 364, &#39;h&#39;: 364}]


Metadata for real_01007(1).jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 54, &#39;w&#39;: 464, &#39;h&#39;: 464}]


Metadata for real_01000.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 93, &#39;w&#39;: 429, &#39;h&#39;: 429}]


Metadata for real_01011.jpg:
[{&#39;x&#39;: 63, &#39;y&#39;: 134, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00963.jpg:
[{&#39;x&#39;: 202, &#39;y&#39;: 176, &#39;w&#39;: 324, &#39;h&#39;: 324}]


Metadata for real_01069.jpg:
[{&#39;x&#39;: 54, &#39;y&#39;: 205, &#39;w&#39;: 354, &#39;h&#39;: 354}]


Metadata for real_00972.jpg:
[{&#39;x&#39;: 48, &#39;y&#39;: 77, &#39;w&#39;: 463, &#39;h&#39;: 463}]


Metadata for real_01036.jpg:
[{&#39;x&#39;: 56, &#39;y&#39;: 166, &#39;w&#39;: 341, &#39;h&#39;: 341}]


Metadata for real_00996.jpg:
[{&#39;x&#39;: 30, &#39;y&#39;: 28, &#39;w&#39;: 539, &#39;h&#39;: 539}]


Metadata for real_00959.jpg:
[{&#39;x&#39;: 142, &#39;y&#39;: 113, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_01055.jpg:
[{&#39;x&#39;: 101, &#39;y&#39;: 165, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_00955.jpg:
[{&#39;x&#39;: 86, &#39;y&#39;: 152, &#39;w&#39;: 388, &#39;h&#39;: 388}]


Metadata for real_00973.jpg:
[{&#39;x&#39;: 161, &#39;y&#39;: 123, &#39;w&#39;: 345, &#39;h&#39;: 345}]


Metadata for real_01029.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 207, &#39;w&#39;: 373, &#39;h&#39;: 373}]


Metadata for real_01060.jpg:
[{&#39;x&#39;: 91, &#39;y&#39;: 130, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_01063.jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 213, &#39;w&#39;: 339, &#39;h&#39;: 339}]


Metadata for real_00976.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 255, &#39;w&#39;: 341, &#39;h&#39;: 341}]


Metadata for real_00974.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 72, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00993.jpg:
[{&#39;x&#39;: 192, &#39;y&#39;: 85, &#39;w&#39;: 359, &#39;h&#39;: 359}]


Metadata for real_01038.jpg:
[{&#39;x&#39;: 183, &#39;y&#39;: 165, &#39;w&#39;: 347, &#39;h&#39;: 347}]


Metadata for real_00988.jpg:
[{&#39;x&#39;: 148, &#39;y&#39;: 154, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00950.jpg:
[{&#39;x&#39;: 140, &#39;y&#39;: 172, &#39;w&#39;: 382, &#39;h&#39;: 382}]


Metadata for real_00997.jpg:
[{&#39;x&#39;: 119, &#39;y&#39;: 422, &#39;w&#39;: 80, &#39;h&#39;: 80}]


Metadata for real_01076.jpg:
[{&#39;x&#39;: 66, &#39;y&#39;: 123, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00982.jpg:
[{&#39;x&#39;: 18, &#39;y&#39;: 92, &#39;w&#39;: 458, &#39;h&#39;: 458}]


Metadata for real_01007.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 54, &#39;w&#39;: 464, &#39;h&#39;: 464}]


Metadata for real_01022.jpg:
[{&#39;x&#39;: 123, &#39;y&#39;: 180, &#39;w&#39;: 357, &#39;h&#39;: 357}]


Metadata for real_01013.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 104, &#39;w&#39;: 57, &#39;h&#39;: 57}]


Metadata for real_00968.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 82, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_01030.jpg:
[{&#39;x&#39;: 150, &#39;y&#39;: 161, &#39;w&#39;: 384, &#39;h&#39;: 384}]


Metadata for real_01043.jpg:
[{&#39;x&#39;: 42, &#39;y&#39;: 138, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00999.jpg:
[{&#39;x&#39;: 92, &#39;y&#39;: 104, &#39;w&#39;: 425, &#39;h&#39;: 425}]


Metadata for real_01071.jpg:
[{&#39;x&#39;: 136, &#39;y&#39;: 207, &#39;w&#39;: 348, &#39;h&#39;: 348}]


Metadata for real_01026.jpg:
[{&#39;x&#39;: 124, &#39;y&#39;: 156, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00979.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 151, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00987.jpg:
[{&#39;x&#39;: 47, &#39;y&#39;: 123, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_01048.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 153, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00991.jpg:
[{&#39;x&#39;: 38, &#39;y&#39;: 122, &#39;w&#39;: 413, &#39;h&#39;: 413}]


Metadata for real_01023.jpg:
[{&#39;x&#39;: 28, &#39;y&#39;: 126, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_01020.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 177, &#39;w&#39;: 396, &#39;h&#39;: 396}]


Metadata for real_00948.jpg:
[{&#39;x&#39;: 43, &#39;y&#39;: 10, &#39;w&#39;: 494, &#39;h&#39;: 494}]


Metadata for real_00983.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 89, &#39;w&#39;: 472, &#39;h&#39;: 472}]


Metadata for real_00960.jpg:
[{&#39;x&#39;: 102, &#39;y&#39;: 197, &#39;w&#39;: 365, &#39;h&#39;: 365}]


Metadata for real_01059.jpg:
[{&#39;x&#39;: 39, &#39;y&#39;: 129, &#39;w&#39;: 409, &#39;h&#39;: 409}]


Metadata for real_00980.jpg:
[{&#39;x&#39;: 22, &#39;y&#39;: 504, &#39;w&#39;: 75, &#39;h&#39;: 75}]


Metadata for real_00989.jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 170, &#39;w&#39;: 374, &#39;h&#39;: 374}]


Metadata for real_01072.jpg:
[{&#39;x&#39;: 98, &#39;y&#39;: 165, &#39;w&#39;: 369, &#39;h&#39;: 369}]


Metadata for real_01058.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 102, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_01045.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 123, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_01018.jpg:
[{&#39;x&#39;: 86, &#39;y&#39;: 103, &#39;w&#39;: 467, &#39;h&#39;: 467}]


Metadata for real_00986.jpg:
[{&#39;x&#39;: 371, &#39;y&#39;: 206, &#39;w&#39;: 187, &#39;h&#39;: 187}, {&#39;x&#39;: 50, &#39;y&#39;: 173, &#39;w&#39;: 341, &#39;h&#39;: 341}]


Metadata for real_01064.jpg:
[{&#39;x&#39;: 113, &#39;y&#39;: 152, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_01066.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 113, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_01009.jpg:
[{&#39;x&#39;: 125, &#39;y&#39;: 153, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_01070.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 146, &#39;w&#39;: 412, &#39;h&#39;: 412}]


Metadata for real_00949.jpg:
[{&#39;x&#39;: 41, &#39;y&#39;: 213, &#39;w&#39;: 50, &#39;h&#39;: 50}, {&#39;x&#39;: 354, &#39;y&#39;: 295, &#39;w&#39;: 60, &#39;h&#39;: 60}]


Metadata for real_01001.jpg:
[{&#39;x&#39;: 462, &#39;y&#39;: 26, &#39;w&#39;: 91, &#39;h&#39;: 91}, {&#39;x&#39;: 86, &#39;y&#39;: 124, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_01003.jpg:
[{&#39;x&#39;: 88, &#39;y&#39;: 141, &#39;w&#39;: 406, &#39;h&#39;: 406}]


Metadata for real_00992.jpg:
[{&#39;x&#39;: 151, &#39;y&#39;: 118, &#39;w&#39;: 435, &#39;h&#39;: 435}]


Metadata for real_01024.jpg:
[{&#39;x&#39;: 52, &#39;y&#39;: 57, &#39;w&#39;: 511, &#39;h&#39;: 511}]


Metadata for real_00966.jpg:
[{&#39;x&#39;: 74, &#39;y&#39;: 8, &#39;w&#39;: 430, &#39;h&#39;: 430}]


Metadata for real_01012.jpg:
[{&#39;x&#39;: 114, &#39;y&#39;: 49, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_01002.jpg:
[{&#39;x&#39;: 49, &#39;y&#39;: 138, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00998.jpg:
[{&#39;x&#39;: 44, &#39;y&#39;: 73, &#39;w&#39;: 480, &#39;h&#39;: 480}]


Metadata for real_01013(1).jpg:
[{&#39;x&#39;: 89, &#39;y&#39;: 104, &#39;w&#39;: 57, &#39;h&#39;: 57}]


Metadata for real_01033.jpg:
[{&#39;x&#39;: 40, &#39;y&#39;: 141, &#39;w&#39;: 392, &#39;h&#39;: 392}]


Metadata for real_01019.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 113, &#39;w&#39;: 458, &#39;h&#39;: 458}]


Metadata for real_01078.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 76, &#39;w&#39;: 468, &#39;h&#39;: 468}]


Metadata for real_01004.jpg:
[{&#39;x&#39;: 51, &#39;y&#39;: 71, &#39;w&#39;: 489, &#39;h&#39;: 489}]


Metadata for real_00965.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 90, &#39;w&#39;: 455, &#39;h&#39;: 455}]


Metadata for real_00861.jpg:
[{&#39;x&#39;: 81, &#39;y&#39;: 56, &#39;w&#39;: 473, &#39;h&#39;: 473}]


Metadata for real_00879.jpg:
[{&#39;x&#39;: 132, &#39;y&#39;: 163, &#39;w&#39;: 389, &#39;h&#39;: 389}]


Metadata for real_00845.jpg:
[{&#39;x&#39;: 62, &#39;y&#39;: 122, &#39;w&#39;: 386, &#39;h&#39;: 386}]


Metadata for real_00840.jpg:
[{&#39;x&#39;: 161, &#39;y&#39;: 138, &#39;w&#39;: 403, &#39;h&#39;: 403}]


Metadata for real_00805.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 139, &#39;w&#39;: 406, &#39;h&#39;: 406}]


Metadata for real_00918.jpg:
[{&#39;x&#39;: 36, &#39;y&#39;: 35, &#39;w&#39;: 478, &#39;h&#39;: 478}]


Metadata for real_00819.jpg:
[{&#39;x&#39;: 60, &#39;y&#39;: 126, &#39;w&#39;: 414, &#39;h&#39;: 414}]


Metadata for real_00796.jpg:
[{&#39;x&#39;: 145, &#39;y&#39;: 125, &#39;w&#39;: 404, &#39;h&#39;: 404}]


Metadata for real_00822.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 119, &#39;w&#39;: 401, &#39;h&#39;: 401}]


Metadata for real_00865.jpg:
[{&#39;x&#39;: 28, &#39;y&#39;: 69, &#39;w&#39;: 492, &#39;h&#39;: 492}]


Metadata for real_00830.jpg:
[{&#39;x&#39;: 96, &#39;y&#39;: 153, &#39;w&#39;: 402, &#39;h&#39;: 402}]


Metadata for real_00854.jpg:
[{&#39;x&#39;: 77, &#39;y&#39;: 110, &#39;w&#39;: 418, &#39;h&#39;: 418}]


Metadata for real_00936.jpg:
[{&#39;x&#39;: 95, &#39;y&#39;: 132, &#39;w&#39;: 432, &#39;h&#39;: 432}]


Metadata for real_00809.jpg:
[{&#39;x&#39;: 83, &#39;y&#39;: 99, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00925.jpg:
[{&#39;x&#39;: 70, &#39;y&#39;: 131, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00831.jpg:
[{&#39;x&#39;: 71, &#39;y&#39;: 101, &#39;w&#39;: 462, &#39;h&#39;: 462}]


Metadata for real_00832.jpg:
[{&#39;x&#39;: 65, &#39;y&#39;: 122, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00795.jpg:
[{&#39;x&#39;: 146, &#39;y&#39;: 156, &#39;w&#39;: 405, &#39;h&#39;: 405}]


Metadata for real_00926.jpg:
[{&#39;x&#39;: 134, &#39;y&#39;: 215, &#39;w&#39;: 370, &#39;h&#39;: 370}]


Metadata for real_00855.jpg:
[{&#39;x&#39;: 156, &#39;y&#39;: 111, &#39;w&#39;: 379, &#39;h&#39;: 379}]


Metadata for real_00806.jpg:
[{&#39;x&#39;: 85, &#39;y&#39;: 147, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00846.jpg:
[{&#39;x&#39;: 76, &#39;y&#39;: 111, &#39;w&#39;: 446, &#39;h&#39;: 446}]


Metadata for real_00814.jpg:
[{&#39;x&#39;: 45, &#39;y&#39;: 75, &#39;w&#39;: 450, &#39;h&#39;: 450}]


Metadata for real_00864.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 145, &#39;w&#39;: 395, &#39;h&#39;: 395}]


Metadata for real_00892.jpg:
[{&#39;x&#39;: 93, &#39;y&#39;: 80, &#39;w&#39;: 431, &#39;h&#39;: 431}]


Metadata for real_00850.jpg:
[{&#39;x&#39;: 112, &#39;y&#39;: 68, &#39;w&#39;: 441, &#39;h&#39;: 441}]


Metadata for real_00906.jpg:
[{&#39;x&#39;: 97, &#39;y&#39;: 143, &#39;w&#39;: 376, &#39;h&#39;: 376}]


Metadata for real_00791.jpg:
[{&#39;x&#39;: 79, &#39;y&#39;: 72, &#39;w&#39;: 437, &#39;h&#39;: 437}]


Metadata for real_00824.jpg:
[{&#39;x&#39;: 68, &#39;y&#39;: 143, &#39;w&#39;: 417, &#39;h&#39;: 417}]


Metadata for real_00862.jpg:
[{&#39;x&#39;: 190, &#39;y&#39;: 198, &#39;w&#39;: 357, &#39;h&#39;: 357}]


Metadata for real_00898.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 168, &#39;w&#39;: 378, &#39;h&#39;: 378}]


Metadata for real_00794.jpg:
[{&#39;x&#39;: 88, &#39;y&#39;: 129, &#39;w&#39;: 422, &#39;h&#39;: 422}]


Metadata for real_00909.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 120, &#39;w&#39;: 426, &#39;h&#39;: 426}]


Metadata for real_00786.jpg:
[{&#39;x&#39;: 91, &#39;y&#39;: 124, &#39;w&#39;: 408, &#39;h&#39;: 408}]


Metadata for real_00903.jpg:
[{&#39;x&#39;: 106, &#39;y&#39;: 171, &#39;w&#39;: 398, &#39;h&#39;: 398}]


Metadata for real_00825.jpg:
[{&#39;x&#39;: 39, &#39;y&#39;: 21, &#39;w&#39;: 493, &#39;h&#39;: 493}]


Metadata for real_00784.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 160, &#39;w&#39;: 415, &#39;h&#39;: 415}]


Metadata for real_00802.jpg:
[{&#39;x&#39;: 91, &#39;y&#39;: 116, &#39;w&#39;: 444, &#39;h&#39;: 444}]


Metadata for real_00934.jpg:
[{&#39;x&#39;: 108, &#39;y&#39;: 153, &#39;w&#39;: 423, &#39;h&#39;: 423}]


Metadata for real_00893.jpg:
[{&#39;x&#39;: 137, &#39;y&#39;: 112, &#39;w&#39;: 419, &#39;h&#39;: 419}]


Metadata for real_00878.jpg:
[{&#39;x&#39;: 111, &#39;y&#39;: 173, &#39;w&#39;: 391, &#39;h&#39;: 391}]


Metadata for real_00994.jpg:
[{&#39;x&#39;: 117, &#39;y&#39;: 43, &#39;w&#39;: 465, &#39;h&#39;: 465}]


Metadata for real_00827.jpg:
[{&#39;x&#39;: 127, &#39;y&#39;: 147, &#39;w&#39;: 362, &#39;h&#39;: 362}, {&#39;x&#39;: 51, &#39;y&#39;: 260, &#39;w&#39;: 58, &#39;h&#39;: 58}]


Metadata for real_00876.jpg:
[{&#39;x&#39;: 115, &#39;y&#39;: 160, &#39;w&#39;: 411, &#39;h&#39;: 411}]


Metadata for real_00871.jpg:
[{&#39;x&#39;: 73, &#39;y&#39;: 124, &#39;w&#39;: 444, &#39;h&#39;: 444}]


</code></pre>
</div>
</div>
<div class="cell markdown" id="SZMURESAq62T">
<p>####4. Generate Embeddings vectors on the each face in the dataset.
<strong>Hint:</strong> Use ‘vgg_face_weights.h5’</p>
</div>
<div class="cell code" data-execution_count="62"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="XotEXbskHGK-" data-outputId="97b98352-8f92-4e63-8743-4c253ab00bb0">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install keras_vggface</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Collecting keras_vggface
  Downloading keras_vggface-0.6-py3-none-any.whl (8.3 kB)
Requirement already satisfied: numpy&gt;=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.22.4)
Requirement already satisfied: scipy&gt;=0.14 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.10.1)
Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (3.8.0)
Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (8.4.0)
Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (2.12.0)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.16.0)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (6.0.1)
Installing collected packages: keras_vggface
Successfully installed keras_vggface-0.6
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="64"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="rFsXL2qyHb3v" data-outputId="a9188b1e-7011-4279-b6e7-eff5ef4a51ea">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install tensorflow keras opencv<span class="op">-</span>python<span class="op">-</span>headless</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)
Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)
Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.0.74)
Requirement already satisfied: absl-py&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)
Requirement already satisfied: astunparse&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)
Requirement already satisfied: flatbuffers&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)
Requirement already satisfied: gast&lt;=0.4.0,&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)
Requirement already satisfied: google-pasta&gt;=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)
Requirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)
Requirement already satisfied: h5py&gt;=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)
Requirement already satisfied: jax&gt;=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)
Requirement already satisfied: libclang&gt;=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)
Requirement already satisfied: numpy&lt;1.24,&gt;=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)
Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)
Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)
Requirement already satisfied: tensorboard&lt;2.13,&gt;=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)
Requirement already satisfied: tensorflow-estimator&lt;2.13,&gt;=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)
Requirement already satisfied: typing-extensions&gt;=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)
Requirement already satisfied: wrapt&lt;1.15,&gt;=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)
Requirement already satisfied: tensorflow-io-gcs-filesystem&gt;=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)
Requirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse&gt;=1.6.0-&gt;tensorflow) (0.40.0)
Requirement already satisfied: ml-dtypes&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax&gt;=0.3.15-&gt;tensorflow) (0.2.0)
Requirement already satisfied: scipy&gt;=1.7 in /usr/local/lib/python3.10/dist-packages (from jax&gt;=0.3.15-&gt;tensorflow) (1.10.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.4.3)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.27.1)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.7.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.3.6)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (5.3.1)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.3.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.4)
Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.1.3)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.2.2)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="66"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="J8P6P7_LHyrH" data-outputId="a1dcb579-6f13-4ed9-cecc-9ebbd9290021">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install tensorflow torch torchvision opencv<span class="op">-</span>python<span class="op">-</span>headless facenet<span class="op">-</span>pytorch</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)
Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.0.74)
Collecting facenet-pytorch
  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 11.1 MB/s eta 0:00:00
ent already satisfied: absl-py&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)
Requirement already satisfied: astunparse&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)
Requirement already satisfied: flatbuffers&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)
Requirement already satisfied: gast&lt;=0.4.0,&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)
Requirement already satisfied: google-pasta&gt;=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)
Requirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)
Requirement already satisfied: h5py&gt;=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)
Requirement already satisfied: jax&gt;=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)
Requirement already satisfied: keras&lt;2.13,&gt;=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)
Requirement already satisfied: libclang&gt;=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)
Requirement already satisfied: numpy&lt;1.24,&gt;=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)
Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)
Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)
Requirement already satisfied: tensorboard&lt;2.13,&gt;=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)
Requirement already satisfied: tensorflow-estimator&lt;2.13,&gt;=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)
Requirement already satisfied: typing-extensions&gt;=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)
Requirement already satisfied: wrapt&lt;1.15,&gt;=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)
Requirement already satisfied: tensorflow-io-gcs-filesystem&gt;=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.6)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)
Requirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse&gt;=1.6.0-&gt;tensorflow) (0.40.0)
Requirement already satisfied: ml-dtypes&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax&gt;=0.3.15-&gt;tensorflow) (0.2.0)
Requirement already satisfied: scipy&gt;=1.7 in /usr/local/lib/python3.10/dist-packages (from jax&gt;=0.3.15-&gt;tensorflow) (1.10.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.7.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (2.3.6)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.3)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (5.3.1)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (1.3.1)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;2.13,&gt;=2.12-&gt;tensorflow) (3.2.2)
Installing collected packages: facenet-pytorch
Successfully installed facenet-pytorch-2.5.3
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="71"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="JJdZrMWeJ9Xu" data-outputId="6bd123f2-0a96-41a7-c009-1e692ea50e9e">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>pip install facenet<span class="op">-</span>pytorch</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.10/dist-packages (2.5.3)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.22.4)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.27.1)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.15.2+cu118)
Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (8.4.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;facenet-pytorch) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;facenet-pytorch) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;facenet-pytorch) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;facenet-pytorch) (3.4)
Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;facenet-pytorch) (2.0.1+cu118)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (3.12.2)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (4.7.1)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (16.0.6)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (2.1.3)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch==2.0.1-&gt;torchvision-&gt;facenet-pytorch) (1.3.0)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="78" id="TcCY1lVYr9vu">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the path to the dataset folder</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>dataset_folder <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/training_images&#39;</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize lists to store images and labels</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> []</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> []</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through the dataset folder</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> folder_name <span class="kw">in</span> os.listdir(dataset_folder):</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>    folder_path <span class="op">=</span> os.path.join(dataset_folder, folder_name)</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.isdir(folder_path):</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the identity label from the folder name</span></span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> <span class="bu">int</span>(folder_name)  <span class="co"># Assuming the folder name is the identity label</span></span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through the images in the folder</span></span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> filename <span class="kw">in</span> os.listdir(folder_path):</span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>        image_path <span class="op">=</span> os.path.join(folder_path, filename)</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess the image if necessary (e.g., resize, normalize)</span></span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>        preprocessed_image <span class="op">=</span> preprocess_image(image)</span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>        X.append(preprocessed_image)</span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>        y.append(label)</span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the lists to numpy arrays</span></span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(X)</span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array(y)</span></code></pre></div>
</div>
<div class="cell markdown" id="FSfmtZaOLbTm">
<p>####5. Build distance metrics for identifying the distance between
two similar and dissimilar images.</p>
</div>
<div class="cell code" data-execution_count="80"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pX4cPXoQLgJl" data-outputId="1ddf8d2b-8cbb-433f-d2c0-d1fd2bd51ada">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> euclidean</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute Euclidean distance between two feature vectors</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> euclidean_distance(vec1, vec2):</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> euclidean(vec1, vec2)</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute cosine similarity between two feature vectors</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cosine_similarity_score(vec1, vec2):</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cosine_similarity([vec1], [vec2])[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage:</span></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming you have two feature vectors vec1 and vec2 obtained from the deep learning model</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>])</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> np.array([<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>])</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Euclidean distance between vec1 and vec2</span></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>euclidean_dist <span class="op">=</span> euclidean_distance(vec1, vec2)</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Euclidean distance:&quot;</span>, euclidean_dist)</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute cosine similarity score between vec1 and vec2</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>cosine_sim <span class="op">=</span> cosine_similarity_score(vec1, vec2)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Cosine similarity score:&quot;</span>, cosine_sim)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Euclidean distance: 0.3872983346207417
Cosine similarity score: 0.8498365855987975
</code></pre>
</div>
</div>
<div class="cell markdown" id="df1UlcLnLoMF">
<p>####6. Use PCA for dimensionality reduction.</p>
</div>
<div class="cell code" data-execution_count="83"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pXXWORWaMxZK" data-outputId="8c89cc13-9d38-4b6d-98da-3e45a921ceef">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install face_recognition</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Collecting face_recognition
  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)
Collecting face-recognition-models&gt;=0.3.0 (from face_recognition)
  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.1/100.1 MB 7.9 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: Click&gt;=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.6)
Requirement already satisfied: dlib&gt;=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)
Building wheels for collected packages: face-recognition-models
  Building wheel for face-recognition-models (setup.py) ... odels: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=88d5accb8ba447e869ed9c348db1c2f8a7aa37867a0574678b6f16c1f76135e4
  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d
Successfully built face-recognition-models
Installing collected packages: face-recognition-models, face_recognition
Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="90"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="uYmEjViSNv6f" data-outputId="16471802-af5c-4f80-9f5c-f253c81252f5">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install face_recognition <span class="op">--</span>no<span class="op">-</span>binary face_recognition</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)
Requirement already satisfied: face-recognition-models&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)
Requirement already satisfied: Click&gt;=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.6)
Requirement already satisfied: dlib&gt;=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)
</code></pre>
</div>
</div>
<div class="cell markdown" id="yWSxOrbhulrG">
<p>####7. Build an SVM classifier in order to map each image to its
right person.</p>
</div>
<div class="cell code" data-execution_count="95"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="vq8S9DncOuCE" data-outputId="bf615d25-61f1-4512-a6bf-df009d04147c">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>nvcc <span class="op">--</span>version</span></code></pre></div>
<div class="output stream stdout">
<pre><code>nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Sep_21_10:33:58_PDT_2022
Cuda compilation tools, release 11.8, V11.8.89
Build cuda_11.8.r11.8/compiler.31833905_0
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="98"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="C_wAbizXO8tT" data-outputId="ec10212d-4af8-4d0f-a213-c427563977ad">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install face_recognition</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)
Requirement already satisfied: face-recognition-models&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)
Requirement already satisfied: Click&gt;=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.6)
Requirement already satisfied: dlib&gt;=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)
</code></pre>
</div>
</div>
<div class="cell markdown" id="-_1i_aFtv204">
<p>####8. Import and display the the test images. <strong>Hint:</strong>
‘Benedict Cumberbatch9.jpg’ and ‘Dwayne Johnson4.jpg’ are the test
images.</p>
</div>
<div class="cell code" data-execution_count="105"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:615}"
id="jT_Lux-jwO2w" data-outputId="344c1d36-5e17-4be3-ad3c-b10952c39f3c">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab.patches <span class="im">import</span> cv2_imshow</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the test images</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>test_image_path1 <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/Benedict Cumberbatch9.jpg&#39;</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>test_image_path2 <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/Dwayne Johnson4.jpg&#39;</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Read and display the first test image</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>test_image1 <span class="op">=</span> cv2.imread(test_image_path1)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>cv2_imshow(test_image1)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Read and display the second test image</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>test_image2 <span class="op">=</span> cv2.imread(test_image_path2)</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>cv2_imshow(test_image2)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/df3da77ed331570e18bd48d36dcefea48e45322a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_efc9b3ffe8e44c9395f2f77f97249bae/6ae8bfb522f1437fd6e8bfd3297ab9aa6c7e6965.png" /></p>
</div>
</div>
<div class="cell markdown" id="rWD-R_hzxoDK">
<p>####9. Use the trained SVM model to predict the face on both test
images.</p>
</div>
<div class="cell code" data-execution_count="109"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="2snUbEfARhyM" data-outputId="7c02cb4a-1247-4a18-c86d-9e7b8ed11a4e">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip uninstall dlib</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dlib<span class="op">-</span>cpu</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Found existing installation: dlib 19.24.2
Uninstalling dlib-19.24.2:
  Would remove:
    /usr/local/lib/python3.10/dist-packages/_dlib_pybind11.cpython-310-x86_64-linux-gnu.so
    /usr/local/lib/python3.10/dist-packages/dlib-19.24.2.dist-info/*
    /usr/local/lib/python3.10/dist-packages/dlib/*
Proceed (Y/n)? y
  Successfully uninstalled dlib-19.24.2
ERROR: Could not find a version that satisfies the requirement dlib-cpu (from versions: none)
ERROR: No matching distribution found for dlib-cpu
</code></pre>
</div>
</div>
<div class="cell code" id="FeNJZz8izAFJ">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> face_recognition</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the SVM model</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.externals <span class="im">import</span> joblib</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>svm_model <span class="op">=</span> joblib.load(<span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/svm_model.pkl&#39;</span>)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the test images</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>test_image_path1 <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/Benedict Cumberbatch9.jpg&#39;</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>test_image_path2 <span class="op">=</span> <span class="st">&#39;/content/drive/MyDrive/Projects/Project/Project-06/Dwayne Johnson4.jpg&#39;</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the test images</span></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>test_image1 <span class="op">=</span> cv2.imread(test_image_path1)</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>test_image2 <span class="op">=</span> cv2.imread(test_image_path2)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to extract faces from images using face_recognition library</span></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_face(image):</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>    face_locations <span class="op">=</span> face_recognition.face_locations(image, model<span class="op">=</span><span class="st">&#39;hog&#39;</span>)</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(face_locations) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>        top, right, bottom, left <span class="op">=</span> face_locations[<span class="dv">0</span>]</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>        face <span class="op">=</span> image[top:bottom, left:right]</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> face</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract faces from test images</span></span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>face1 <span class="op">=</span> extract_face(test_image1)</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>face2 <span class="op">=</span> extract_face(test_image2)</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if faces are detected</span></span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> face1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> face2 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resize faces to VGGFace input size (224x224)</span></span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a>    face1 <span class="op">=</span> cv2.resize(face1, (<span class="dv">224</span>, <span class="dv">224</span>))</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a>    face2 <span class="op">=</span> cv2.resize(face2, (<span class="dv">224</span>, <span class="dv">224</span>))</span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the faces to RGB (face_recognition expects RGB format)</span></span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>    face1_rgb <span class="op">=</span> cv2.cvtColor(face1, cv2.COLOR_BGR2RGB)</span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>    face2_rgb <span class="op">=</span> cv2.cvtColor(face2, cv2.COLOR_BGR2RGB)</span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-40"><a href="#cb65-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if faces belong to the same person using face_recognition library</span></span>
<span id="cb65-41"><a href="#cb65-41" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> face_recognition.compare_faces([face1_rgb], face2_rgb)[<span class="dv">0</span>]</span>
<span id="cb65-42"><a href="#cb65-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-43"><a href="#cb65-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the prediction</span></span>
<span id="cb65-44"><a href="#cb65-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prediction:</span>
<span id="cb65-45"><a href="#cb65-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;The faces belong to the same person.&quot;</span>)</span>
<span id="cb65-46"><a href="#cb65-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb65-47"><a href="#cb65-47" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;The faces belong to different persons.&quot;</span>)</span>
<span id="cb65-48"><a href="#cb65-48" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb65-49"><a href="#cb65-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Faces not detected in both images.&quot;</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="aH4yHSLGyJT3">
<p>#<strong>Project is Done</strong></p>
<hr />
<p>##<strong>Thank You.</strong></p>
</div>
</body>
</html>
